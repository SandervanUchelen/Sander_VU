{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9700708,"sourceType":"datasetVersion","datasetId":5932068}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-27T12:38:55.393652Z","iopub.execute_input":"2024-11-27T12:38:55.394592Z","iopub.status.idle":"2024-11-27T12:38:55.400915Z","shell.execute_reply.started":"2024-11-27T12:38:55.394555Z","shell.execute_reply":"2024-11-27T12:38:55.399865Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/2020-2021_GOOD.csv\n/kaggle/input/2019-2020_GOOD.csv\n/kaggle/input/2022-2023_GOOD.csv\n/kaggle/input/2018-2019_GOOD.csv\n/kaggle/input/2021-2022_GOOD.csv\n/kaggle/input/2023-2024_GOOD.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"LOADING THE NEEDED PACKAGES","metadata":{}},{"cell_type":"code","source":"!pip install torch\n!pip install pytorch-tabnet\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T12:38:57.527220Z","iopub.execute_input":"2024-11-27T12:38:57.527599Z","iopub.status.idle":"2024-11-27T12:39:15.283371Z","shell.execute_reply.started":"2024-11-27T12:38:57.527568Z","shell.execute_reply":"2024-11-27T12:39:15.282352Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nCollecting pytorch-tabnet\n  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (1.26.4)\nRequirement already satisfied: scikit_learn>0.21 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (1.2.2)\nRequirement already satisfied: scipy>1.4 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (1.14.1)\nRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (2.4.0)\nRequirement already satisfied: tqdm>=4.36 in /opt/conda/lib/python3.10/site-packages (from pytorch-tabnet) (4.66.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit_learn>0.21->pytorch-tabnet) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit_learn>0.21->pytorch-tabnet) (3.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->pytorch-tabnet) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\nDownloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pytorch-tabnet\nSuccessfully installed pytorch-tabnet-4.1.0\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom imblearn.over_sampling import SMOTE\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom boruta import BorutaPy\n\nimport optuna\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import make_scorer, f1_score, accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import cross_val_score\nfrom collections import Counter\n\nimport xgboost\nfrom xgboost import XGBClassifier\n\nimport torch\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nimport optuna.visualization.matplotlib as optuna_vis\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-27T12:39:20.059768Z","iopub.execute_input":"2024-11-27T12:39:20.060131Z","iopub.status.idle":"2024-11-27T12:39:20.072057Z","shell.execute_reply.started":"2024-11-27T12:39:20.060085Z","shell.execute_reply":"2024-11-27T12:39:20.071206Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"**LOADING IN THE DATA**\n\n","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/'\n\n# List files in the directory to confirm their existence\nprint(os.listdir(data_dir))\n\n# Define file paths\ntraining2018 = os.path.join(data_dir, '2018-2019_GOOD.csv')\ntraining2019 = os.path.join(data_dir, '2019-2020_GOOD.csv')\ntraining2020 = os.path.join(data_dir, '2020-2021_GOOD.csv')\ntraining2021 = os.path.join(data_dir, '2021-2022_GOOD.csv')\ntraining2022 = os.path.join(data_dir, '2022-2023_GOOD.csv')\ntestset = os.path.join(data_dir, '2023-2024_GOOD.csv')\n\n# \ndf_2018 = pd.read_csv(training2018, sep=';')\ndf_2019 = pd.read_csv(training2019, sep=';')\ndf_2020 = pd.read_csv(training2020, sep=';')\ndf_2021 = pd.read_csv(training2021, sep=';')\ndf_2022 = pd.read_csv(training2022, sep=';')\ndf_Tes = pd.read_csv(testset, sep=';')","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:39:23.330655Z","iopub.execute_input":"2024-11-27T12:39:23.331018Z","iopub.status.idle":"2024-11-27T12:39:23.388386Z","shell.execute_reply.started":"2024-11-27T12:39:23.330988Z","shell.execute_reply":"2024-11-27T12:39:23.386968Z"},"trusted":true},"outputs":[{"name":"stdout","text":"['2020-2021_GOOD.csv', '2019-2020_GOOD.csv', '2022-2023_GOOD.csv', '2018-2019_GOOD.csv', '2021-2022_GOOD.csv', '2023-2024_GOOD.csv']\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"**PREPROCESSING - FEATURE TRANSFORMATION**\n","metadata":{}},{"cell_type":"code","source":"# Function to process each dataframe (convert 'Date' to datetime, extract 'Day_of_Week', categorize 'Time')\ndef process_dataframe(df):\n    # Convert 'Date' to datetime and get the day of the week\n    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n    df['Day_of_Week'] = df['Date'].dt.strftime('%A')\n    \n    # Categorize 'Day_of_Week' to make it a categorical variable\n    df['Day_of_Week'] = pd.Categorical(df['Day_of_Week'], categories=['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'], ordered=True)\n\n    # Convert 'Time' to proper time format without seconds\n    df['Time'] = pd.to_datetime(df['Time'], format='%H:%M', errors='coerce').dt.time\n\n    # Function to categorize time into parts of the day\n    def categorize_time(time):\n        if pd.isnull(time):\n            return 'Unknown'\n        elif time >= pd.to_datetime('12:00').time() and time < pd.to_datetime('15:00').time():\n            return 'Early Afternoon'\n        elif time >= pd.to_datetime('15:00').time() and time < pd.to_datetime('18:00').time():\n            return 'Late Afternoon'\n        elif time >= pd.to_datetime('18:00').time() and time <= pd.to_datetime('23:59').time():\n            return 'Evening'\n        else:\n            return 'Morning'\n    \n    # Apply the time categorization function\n    df['Time_Category'] = df['Time'].apply(categorize_time)\n    \n    def assign_points(ftr):\n        if ftr == 'H':  # Home team won\n            return pd.Series({'HPG': 3, 'APG': 0})\n        elif ftr == 'A':  # Away team won\n            return pd.Series({'HPG': 0, 'APG': 3})\n        elif ftr == 'D':  # Draw\n            return pd.Series({'HPG': 1, 'APG': 1})\n        else:\n            return pd.Series({'HPG': None, 'APG': None})  # Voor missende waarden\n\n    # Pas de functie toe om 'HPG' (Home Points Gained) en 'APG' (Away Points Gained) te maken\n    df[['HFPG', 'AFPG']] = df['FTR'].apply(assign_points)\n    df[['HHPG', 'AHPG']] = df['HTR'].apply(assign_points)\n    \n    return df\n\n# List of dataframes to process (replace df_2019, df_2020, etc., with your actual dataframes)\ndfs = [df_2018, df_2019, df_2020, df_2021, df_2022, df_Tes]\n\n# Process all dataframes using a loop and reassign them\nfor i in range(len(dfs)):\n    dfs[i] = process_dataframe(dfs[i])\n\n# Assign the processed dataframes back to their original names\ndf_2018, df_2019, df_2020, df_2021, df_2022, df_Tes = dfs\n","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:39:26.075032Z","iopub.execute_input":"2024-11-27T12:39:26.075797Z","iopub.status.idle":"2024-11-27T12:39:29.148824Z","shell.execute_reply.started":"2024-11-27T12:39:26.075763Z","shell.execute_reply":"2024-11-27T12:39:29.147859Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def calculate_previous_match_stats(df, features_home, features_away, window=5):\n    df = df.copy()\n    df.sort_values(by='Date', inplace=True)  # Sorteer op datum\n    teams = pd.concat([df['HomeTeam'], df['AwayTeam']]).unique()  # Unieke teams vinden\n\n    # Initialiseer de nieuwe kolommen met NaN\n    for feature_home, feature_away in zip(features_home, features_away):\n        df[f'{feature_home}_HomeAvg'] = np.nan\n        df[f'{feature_away}_AwayAvg'] = np.nan\n\n    # Bereken rolling averages voor elk team, zowel thuis als uit\n    for team in teams:\n        # Filter de wedstrijden waar het team speelde (thuis of uit)\n        team_matches = df[(df['HomeTeam'] == team) | (df['AwayTeam'] == team)].copy()\n        team_matches = team_matches.sort_values(by='Date')\n\n        # Doorloop elke wedstrijd en bereken het gemiddelde op basis van eerdere wedstrijden\n        for i, match in team_matches.iterrows():\n            # Selecteer de laatste 'window' aantal wedstrijden van het team\n            past_matches = team_matches[team_matches['Date'] < match['Date']].tail(window)\n\n            # Alleen verdergaan als er eerdere wedstrijden zijn\n            if len(past_matches) > 0:\n                # Bereken rolling averages voor de laatste 'window' aantal wedstrijden\n                for feature_home, feature_away in zip(features_home, features_away):\n                    # Voor thuisteam statistieken\n                    if match['HomeTeam'] == team:\n                        feature_values = pd.concat([\n                            past_matches.loc[past_matches['HomeTeam'] == team, feature_home],\n                            past_matches.loc[past_matches['AwayTeam'] == team, feature_away]\n                        ])\n                        home_avg = feature_values.mean()\n                        df.loc[i, f'{feature_home}_HomeAvg'] = round(home_avg, 2)  # Afronden op 2 decimalen\n\n                    # Voor uitteam statistieken\n                    if match['AwayTeam'] == team:\n                        feature_values = pd.concat([\n                            past_matches.loc[past_matches['HomeTeam'] == team, feature_home],\n                            past_matches.loc[past_matches['AwayTeam'] == team, feature_away]\n                        ])\n                        away_avg = feature_values.mean()\n                        df.loc[i, f'{feature_away}_AwayAvg'] = round(away_avg, 2)  # Afronden op 2 decimalen\n            else:\n                # Als er geen eerdere wedstrijden zijn, laten we de waarden als NaN staan\n                for feature_home, feature_away in zip(features_home, features_away):\n                    df.loc[i, f'{feature_home}_HomeAvg'] = np.nan\n                    df.loc[i, f'{feature_away}_AwayAvg'] = np.nan\n\n    # Verwijder de oude kolommen die nu overbodig zijn\n    all_features = features_home + features_away\n    df = df.drop(columns=all_features, errors='ignore')\n\n    return df\n\n# Specificaties van features voor thuis en uit\nfeatures_HOME = ['HS', 'HST', 'HF', 'HC', 'HY', 'HR', 'FTHG', 'HTHG', 'HFPG', 'HHPG']  # Thuisteam statistieken\nfeatures_AWAY = ['AS', 'AST', 'AF', 'AC', 'AY', 'AR', 'FTAG', 'HTAG', 'AFPG', 'AHPG']  # Uitteam statistieken\n\n# Voorbeeld dataframes gebruiken om de functie te testen\ndf_2018 = calculate_previous_match_stats(df_2018, features_HOME, features_AWAY, window=5)\ndf_2019 = calculate_previous_match_stats(df_2019, features_HOME, features_AWAY, window=5)\ndf_2020 = calculate_previous_match_stats(df_2020, features_HOME, features_AWAY, window=5)\ndf_2021 = calculate_previous_match_stats(df_2021, features_HOME, features_AWAY, window=5)\ndf_2022 = calculate_previous_match_stats(df_2022, features_HOME, features_AWAY, window=5)\ndf_Tes = calculate_previous_match_stats(df_Tes, features_HOME, features_AWAY, window=5)","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:44:26.811860Z","iopub.execute_input":"2024-11-27T12:44:26.812514Z","iopub.status.idle":"2024-11-27T12:45:13.927740Z","shell.execute_reply.started":"2024-11-27T12:44:26.812479Z","shell.execute_reply":"2024-11-27T12:45:13.926988Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"features_HOME_AVG = ['HS_HomeAvg', 'HST_HomeAvg', 'HF_HomeAvg', 'HC_HomeAvg', 'HY_HomeAvg', 'HR_HomeAvg', 'FTHG_HomeAvg', 'HTHG_HomeAvg', 'HFPG_HomeAvg', 'HHPG_HomeAvg', 'FRHDEF', 'FRHMID', 'FRHATT', 'FRHAVG']\nfeatures_AWAY_AVG = ['AS_AwayAvg', 'AST_AwayAvg', 'AF_AwayAvg', 'AC_AwayAvg', 'AY_AwayAvg', 'AR_AwayAvg', 'FTAG_AwayAvg', 'HTAG_AwayAvg', 'AFPG_AwayAvg', 'AHPG_AwayAvg', 'FRADEF', 'FRAMID', 'FRAATT', 'FRAAVG']\n\nfeatures_Home_Processed = ['S', 'ST', 'F', 'C', 'Y', 'R', 'FTG', 'HTG', 'FPG', 'HPG', 'FRDEF', 'FRMID', 'FRATT', 'FRAVG']\n\ndef add_difference_columns(df, features_Home_Processed, features_AWAY_AVG, features_HOME_AVG):\n    df = df.copy()\n    \n    # Voor elke feature in de verwerkte lijst\n    for i in range(len(features_Home_Processed)):\n        # Namen van de kolommen\n        home_avg_col = features_HOME_AVG[i]\n        away_avg_col = features_AWAY_AVG[i]\n        diff_col = f'Diff_{features_Home_Processed[i]}'\n\n        # Bereken het verschil en sla dit op in een nieuwe kolom\n        df[diff_col] = df[home_avg_col] - df[away_avg_col]\n        \n    return df\n\n# Pas de functie toe op je datasets\ndf_2018 = add_difference_columns(df_2018, features_Home_Processed, features_AWAY_AVG, features_HOME_AVG)\ndf_2019 = add_difference_columns(df_2019, features_Home_Processed, features_AWAY_AVG, features_HOME_AVG)\ndf_2020 = add_difference_columns(df_2020, features_Home_Processed, features_AWAY_AVG, features_HOME_AVG)\ndf_2021 = add_difference_columns(df_2021, features_Home_Processed, features_AWAY_AVG, features_HOME_AVG)\ndf_2022 = add_difference_columns(df_2022, features_Home_Processed, features_AWAY_AVG, features_HOME_AVG)\ndf_Tes = add_difference_columns(df_Tes, features_Home_Processed, features_AWAY_AVG, features_HOME_AVG)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:45:20.493297Z","iopub.execute_input":"2024-11-27T12:45:20.494036Z","iopub.status.idle":"2024-11-27T12:45:20.541067Z","shell.execute_reply.started":"2024-11-27T12:45:20.494001Z","shell.execute_reply":"2024-11-27T12:45:20.539862Z"},"trusted":true},"outputs":[],"execution_count":11},{"cell_type":"code","source":"#Samenvoegen trainingsdata\nfinal_training= pd.concat([df_2018, df_2019, df_2020, df_2021, df_2022], axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:45:24.282974Z","iopub.execute_input":"2024-11-27T12:45:24.283796Z","iopub.status.idle":"2024-11-27T12:45:24.291965Z","shell.execute_reply.started":"2024-11-27T12:45:24.283761Z","shell.execute_reply":"2024-11-27T12:45:24.291193Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Verwijder 'Time', 'Date', 'Div', 'HTR' en andere opgegeven kolommen\ncolumns_to_drop = ['Time', 'Date', 'Div', 'HTR'] + features_HOME_AVG + features_AWAY_AVG\ndata = final_training.drop(columns=columns_to_drop, errors='ignore')\ndf_Tes = df_Tes.drop(columns=columns_to_drop, errors='ignore')","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:45:28.296737Z","iopub.execute_input":"2024-11-27T12:45:28.297090Z","iopub.status.idle":"2024-11-27T12:45:28.304619Z","shell.execute_reply.started":"2024-11-27T12:45:28.297062Z","shell.execute_reply":"2024-11-27T12:45:28.303860Z"},"trusted":true},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(data.head())\nprint(df_Tes.head())","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:45:35.337561Z","iopub.execute_input":"2024-11-27T12:45:35.338388Z","iopub.status.idle":"2024-11-27T12:45:35.359999Z","shell.execute_reply.started":"2024-11-27T12:45:35.338354Z","shell.execute_reply":"2024-11-27T12:45:35.359164Z"},"trusted":true},"outputs":[{"name":"stdout","text":"       HomeTeam        AwayTeam FTR     Referee  B365H  B365D  B365A  \\\n0    Man United       Leicester   H  A Marriner   1.57    3.9   7.50   \n1   Bournemouth         Cardiff   H    K Friend   1.90    3.6   4.50   \n2        Fulham  Crystal Palace   A      M Dean   2.50    3.4   3.00   \n3  Huddersfield         Chelsea   A  C Kavanagh   6.50    4.0   1.61   \n4     Newcastle       Tottenham   A  M Atkinson   3.90    3.5   2.04   \n\n  Day_of_Week    Time_Category  Diff_S  ...  Diff_Y  Diff_R  Diff_FTG  \\\n0      Friday          Evening     NaN  ...     NaN     NaN       NaN   \n1    Saturday   Late Afternoon     NaN  ...     NaN     NaN       NaN   \n2    Saturday   Late Afternoon     NaN  ...     NaN     NaN       NaN   \n3    Saturday   Late Afternoon     NaN  ...     NaN     NaN       NaN   \n4    Saturday  Early Afternoon     NaN  ...     NaN     NaN       NaN   \n\n   Diff_HTG  Diff_FPG  Diff_HPG  Diff_FRDEF  Diff_FRMID  Diff_FRATT  \\\n0       NaN       NaN       NaN           5           7           4   \n1       NaN       NaN       NaN           4           1           3   \n2       NaN       NaN       NaN          -3           1          -1   \n3       NaN       NaN       NaN          -9         -10          -7   \n4       NaN       NaN       NaN         -13          -7          -6   \n\n   Diff_FRAVG  \n0           5  \n1           3  \n2          -1  \n3          -8  \n4          -7  \n\n[5 rows x 23 columns]\n      HomeTeam       AwayTeam FTR    Referee  B365H  B365D  B365A Day_of_Week  \\\n0      Burnley       Man City   A   C Pawson   8.00    5.5   1.33      Friday   \n1      Arsenal  Nott'm Forest   H   M Oliver   1.18    7.0  15.00    Saturday   \n2  Bournemouth       West Ham   D   P Bankes   2.70    3.4   2.55    Saturday   \n3     Brighton          Luton   H    D Coote   1.33    5.5   9.00    Saturday   \n4      Everton         Fulham   A  S Attwell   2.20    3.4   3.30    Saturday   \n\n     Time_Category  Diff_S  ...  Diff_Y  Diff_R  Diff_FTG  Diff_HTG  Diff_FPG  \\\n0          Evening     NaN  ...     NaN     NaN       NaN       NaN       NaN   \n1  Early Afternoon     NaN  ...     NaN     NaN       NaN       NaN       NaN   \n2   Late Afternoon     NaN  ...     NaN     NaN       NaN       NaN       NaN   \n3   Late Afternoon     NaN  ...     NaN     NaN       NaN       NaN       NaN   \n4   Late Afternoon     NaN  ...     NaN     NaN       NaN       NaN       NaN   \n\n   Diff_HPG  Diff_FRDEF  Diff_FRMID  Diff_FRATT  Diff_FRAVG  \n0       NaN         -14         -13         -10         -11  \n1       NaN           7           8           6           6  \n2       NaN          -3          -3          -3          -4  \n3       NaN           4           7           6           5  \n4       NaN           2          -1          -1           0  \n\n[5 rows x 23 columns]\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"**DATA PREPARATION - HANDLING MISSING VALUES**","metadata":{}},{"cell_type":"code","source":"# Checking for missing values\n# Totaal aantal missende waarden in de DataFrames\ntotal_missing_data = data.isna().sum().sum()\ntotal_missing_df_Tes = df_Tes.isna().sum().sum()\n\n# Print het totale aantal missende waarden voor elke DataFrame\nprint(f'Total missing values in df_training: {total_missing_data}')\nprint(f'Total missing values in df_test: {total_missing_df_Tes}')","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:45:41.062498Z","iopub.execute_input":"2024-11-27T12:45:41.063301Z","iopub.status.idle":"2024-11-27T12:45:41.072862Z","shell.execute_reply.started":"2024-11-27T12:45:41.063268Z","shell.execute_reply":"2024-11-27T12:45:41.071873Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Total missing values in df_training: 520\nTotal missing values in df_test: 100\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Verondersteld dat je pandas al hebt geïmporteerd en de datasets hebt ingeladen\ndata_cleaned = data.dropna()\ndf_Tes_cleaned = df_Tes.dropna()\n\n# Controleer de nieuwe vorm (aantal rijen en kolommen) van de opgeschoonde DataFrames\nprint(data_cleaned.shape)\nprint(df_Tes_cleaned.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:45:43.988404Z","iopub.execute_input":"2024-11-27T12:45:43.989030Z","iopub.status.idle":"2024-11-27T12:45:43.999372Z","shell.execute_reply.started":"2024-11-27T12:45:43.988997Z","shell.execute_reply":"2024-11-27T12:45:43.998583Z"},"trusted":true},"outputs":[{"name":"stdout","text":"(1848, 23)\n(370, 23)\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"**DATA PREPARATION - LABEL ENCODING**","metadata":{}},{"cell_type":"code","source":"# Maak een kopie van de originele datasets\ndata_original = data_cleaned.copy()\ndf_test = df_Tes_cleaned.copy()\n\n# Voeg een kolom toe aan beide datasets\n\ndata_original['Set'] = 1# 1 voor trainingsdata\ndf_test['Set'] = 2        # 2 voor testdata\n\n# Combineer de datasets\ncombined_data = pd.concat([data_original, df_test], ignore_index=True)\n\n# LABEL ENCODING\n# Stap 2: Identificeer categorische kolommen voor label encoding\ncategorical_columns = combined_data.select_dtypes(include=['object']).columns.tolist()\nprint(\"Categorische kolommen:\", categorical_columns)\n\n# Controleer en voeg 'Day_of_Week' toe aan de lijst van categorische kolommen als het niet aanwezig is\nif 'Day_of_Week' not in categorical_columns:\n    categorical_columns.append('Day_of_Week')\n\n# Initialiseer de LabelEncoder\nlabel_encoders = {}  # Opslaan van label encoders voor eventueel later gebruik\n\n# Pas Label Encoding toe op de categorische kolommen en sla deze op in combined_data\nfor col in categorical_columns:\n    if col in combined_data.columns:  # Zorg ervoor dat de kolom bestaat\n        le = LabelEncoder()\n        combined_data[col] = le.fit_transform(combined_data[col])\n        label_encoders[col] = le  # Bewaar de label encoder voor later gebruik\n\nprint(combined_data.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:45:47.421242Z","iopub.execute_input":"2024-11-27T12:45:47.421550Z","iopub.status.idle":"2024-11-27T12:45:47.445499Z","shell.execute_reply.started":"2024-11-27T12:45:47.421525Z","shell.execute_reply":"2024-11-27T12:45:47.444777Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Categorische kolommen: ['HomeTeam', 'AwayTeam', 'FTR', 'Referee', 'Time_Category']\n   HomeTeam  AwayTeam  FTR  Referee  B365H  B365D  B365A  Day_of_Week  \\\n0        26         2    0       32   2.10    3.6   3.70            2   \n1        23        10    2        3   1.28    6.0  12.00            2   \n2        13        27    2       20   2.04    3.5   3.90            2   \n3         7         0    2       19   1.80    4.0   4.50            2   \n4         6        18    1        5   3.25    3.1   2.54            2   \n\n   Time_Category  Diff_S  ...  Diff_R  Diff_FTG  Diff_HTG  Diff_FPG  Diff_HPG  \\\n0              2    -7.0  ...     0.0      -2.0      -1.0      -3.0      -3.0   \n1              2     0.0  ...     0.0       2.0       2.0       3.0       3.0   \n2              2     2.0  ...     0.0      -1.0      -1.0      -1.0      -1.0   \n3              2     4.0  ...     0.0       3.0       2.0       3.0       3.0   \n4              0    -5.0  ...     0.0      -1.0      -1.0       0.0       0.0   \n\n   Diff_FRDEF  Diff_FRMID  Diff_FRATT  Diff_FRAVG  Set  \n0           2           3           0           3    1  \n1          13           6           8           7    1  \n2           4          -3           2           2    1  \n3          -1           3           1           1    1  \n4          -3          -2          -3          -3    1  \n\n[5 rows x 24 columns]\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"train_data = combined_data[combined_data['Set'] == 1].drop(columns=['Set'])\ntest_data = combined_data[combined_data['Set'] == 2].drop(columns=['Set'])\n\n# Nu zijn train_data en test_data klaar voor gebruik\nprint(\"Train Data:\")\nprint(train_data.head())\nprint(train_data.shape)\nprint(\"\\nTest Data:\")\nprint(test_data.head())","metadata":{"execution":{"iopub.status.busy":"2024-11-27T12:45:50.946291Z","iopub.execute_input":"2024-11-27T12:45:50.946604Z","iopub.status.idle":"2024-11-27T12:45:50.970623Z","shell.execute_reply.started":"2024-11-27T12:45:50.946577Z","shell.execute_reply":"2024-11-27T12:45:50.969745Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train Data:\n   HomeTeam  AwayTeam  FTR  Referee  B365H  B365D  B365A  Day_of_Week  \\\n0        26         2    0       32   2.10    3.6   3.70            2   \n1        23        10    2        3   1.28    6.0  12.00            2   \n2        13        27    2       20   2.04    3.5   3.90            2   \n3         7         0    2       19   1.80    4.0   4.50            2   \n4         6        18    1        5   3.25    3.1   2.54            2   \n\n   Time_Category  Diff_S  ...  Diff_Y  Diff_R  Diff_FTG  Diff_HTG  Diff_FPG  \\\n0              2    -7.0  ...     1.0     0.0      -2.0      -1.0      -3.0   \n1              2     0.0  ...     1.0     0.0       2.0       2.0       3.0   \n2              2     2.0  ...     1.0     0.0      -1.0      -1.0      -1.0   \n3              2     4.0  ...    -1.0     0.0       3.0       2.0       3.0   \n4              0    -5.0  ...    -1.0     0.0      -1.0      -1.0       0.0   \n\n   Diff_HPG  Diff_FRDEF  Diff_FRMID  Diff_FRATT  Diff_FRAVG  \n0      -3.0           2           3           0           3  \n1       3.0          13           6           8           7  \n2      -1.0           4          -3           2           2  \n3       3.0          -1           3           1           1  \n4       0.0          -3          -2          -3          -3  \n\n[5 rows x 23 columns]\n(1848, 23)\n\nTest Data:\n      HomeTeam  AwayTeam  FTR  Referee  B365H  B365D  B365A  Day_of_Week  \\\n1848        20        21    2       25   1.95    3.4   4.00            0   \n1849        10         3    0        6   2.70    3.3   2.63            2   \n1850        14         2    2       37   1.20    7.0  13.00            2   \n1851        27         4    0        0   4.00    3.8   1.85            2   \n1852        23        17    2       22   2.80    3.6   2.38            2   \n\n      Time_Category  Diff_S  ...  Diff_Y  Diff_R  Diff_FTG  Diff_HTG  \\\n1848              1    -2.0  ...    -1.0     0.0       1.0       0.0   \n1849              2    -2.0  ...     1.0     0.0      -1.0      -2.0   \n1850              2    -1.0  ...     2.0     0.0       0.0       1.0   \n1851              2    -4.0  ...     1.0     0.0      -4.0      -1.0   \n1852              2     3.0  ...     2.0     0.0       1.0       2.0   \n\n      Diff_FPG  Diff_HPG  Diff_FRDEF  Diff_FRMID  Diff_FRATT  Diff_FRAVG  \n1848       0.0      -1.0           7           3           3           4  \n1849       2.0       0.0           2           1           0           0  \n1850       0.0       0.0          10           7          10           9  \n1851      -3.0      -2.0           2          -1          -3           0  \n1852      -2.0       0.0           1          -2          -3          -1  \n\n[5 rows x 23 columns]\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"**EDA**","metadata":{}},{"cell_type":"code","source":"# Correlatiematrix berekenen voor de volledige trainingset\ncorrelation_matrix = train_data.corr()\n\n# Plot de volledige correlatiematrix\nplt.figure(figsize=(16, 10))\nsns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='PuOr', linewidths=0.5)\nplt.title(f'Correlation Matrix', fontsize=14, weight='bold')\nplt.xlabel('Features', fontsize=12)\nplt.ylabel('Features', fontsize=12)\n\nplt.tight_layout()\nplt.savefig(f'Correlation_Matrix.png', format='png')  # Save as high-quality PNG\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-26T10:57:55.005878Z","iopub.execute_input":"2024-11-26T10:57:55.006213Z","iopub.status.idle":"2024-11-26T10:57:57.419989Z","shell.execute_reply.started":"2024-11-26T10:57:55.006184Z","shell.execute_reply":"2024-11-26T10:57:57.419153Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the mapping for FTR labels\nftr_mapping = {0: 'A', 1: 'D', 2: 'H'}\n\n# Apply the mapping to the 'FTR' column\ntrain_data['FTR'] = train_data['FTR'].map(ftr_mapping)\n\n# Select all columns except 'FTR' (the target column)\nall_features = [col for col in train_data.columns if col != 'FTR']\n\n# Create the figure for the boxplots\nplt.figure(figsize=(18, 20))  # Adjusting the figure size to fit all plots\n\n# Total number of features to plot\nn_features = len(all_features)\n\n# Loop through the features and create a boxplot for each one\nfor i, feature in enumerate(all_features):\n    plt.subplot((n_features // 3) + 1, 3, i + 1)  # Organizing into rows and columns\n    sns.boxplot(x='FTR', y=feature, data=train_data, palette='PuOr', showfliers=False)  # Hiding the outliers\n    plt.title(f'Boxplot of {feature} by FTR')\n    plt.xlabel('FTR Outcome')\n    plt.ylabel(feature)\n\n# Adjust the layout to ensure everything fits well\nplt.tight_layout()\nplt.savefig(f'Boxplots.png', format='png')\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-26T10:58:05.122091Z","iopub.execute_input":"2024-11-26T10:58:05.122873Z","iopub.status.idle":"2024-11-26T10:58:09.598202Z","shell.execute_reply.started":"2024-11-26T10:58:05.122823Z","shell.execute_reply":"2024-11-26T10:58:09.597319Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set(style=\"whitegrid\")\n\n# Define the mapping for FTR labels\nftr_mapping = {0: 'A', 1: 'D', 2: 'H'}\n\norder = ['H', 'D', 'A']\n# Apply the mapping to the 'FTR' column\ntrain_data['FTR'] = train_data['FTR'].map(ftr_mapping)\n\n# Specify the features and group them for the desired layout\ntop_row_features = ['B365H', 'B365A']\nbottom_row_features = ['Diff_HPG', 'Diff_HTG']\n\n# Create the figure for the boxplots\nplt.figure(figsize=(12, 6))  # Adjusting the figure size to fit the selected plots\n\n# Loop through the top row features and create a boxplot for each one\nfor i, feature in enumerate(top_row_features):\n    plt.subplot(2, 2, i + 1)  # Organizing the plots into two rows and two columns\n    sns.boxplot(x='FTR', y=feature, data=train_data, palette='PuOr', showfliers=False, order = order)  # Hide outliers\n    plt.title(f'Boxplot of {feature} by FTR')\n    plt.xlabel('FTR Outcome')\n    plt.ylabel(feature)\n\n# Loop through the bottom row features and create a boxplot for each one\nfor i, feature in enumerate(bottom_row_features):\n    plt.subplot(2, 2, len(top_row_features) + i + 1)  # Continue the layout for the bottom row\n    sns.boxplot(x='FTR', y=feature, data=train_data, palette='PuOr', showfliers=False, order = order)  # Hide outliers\n    plt.title(f'Boxplot of {feature} by FTR')\n    plt.xlabel('FTR Outcome')\n    plt.ylabel(feature)\n\n# Adjust the layout to ensure everything fits well\nplt.tight_layout()\nplt.savefig('boxplot_by_FTR.png', format='png', dpi=300)  # Save as high-quality PNG\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T14:16:48.054864Z","iopub.execute_input":"2024-11-06T14:16:48.055328Z","iopub.status.idle":"2024-11-06T14:16:50.062650Z","shell.execute_reply.started":"2024-11-06T14:16:48.055287Z","shell.execute_reply":"2024-11-06T14:16:50.061389Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Data preparation**","metadata":{}},{"cell_type":"code","source":"# Functie om datasetvarianten te maken\ndef create_data_variants(X, y, add_odds, balance_data):\n    # Lijst met kolommen die betrekking hebben op odds\n    odds_columns = ['B365H', 'B365D', 'B365A']\n\n    # Verwijder de odds-kolommen als add_odds False is\n    if not add_odds:\n        X = X.drop(columns=odds_columns, errors='ignore')\n\n    # Balanceren van de data met SMOTE indien balance_data True is\n    if balance_data:\n        smote = SMOTE(random_state=42)\n        X, y = smote.fit_resample(X, y)\n    \n    return X, y\n\n# Hoofdfunctie voor datasetvoorbereiding\ndef prepare_datasets(train_data, test_data, target_column='FTR', add_odds=True):\n    # Scheid de features van de target\n    X = train_data.drop(columns=[target_column])\n    y = train_data[target_column]\n\n    # Dataset varianten\n    datasets = {}\n\n    # Variaties maken van de trainingset\n    datasets['trainmet_odds_met_balancing'] = create_data_variants(X, y, add_odds=True, balance_data=True)\n    datasets['trainmet_odds_zonder_balancing'] = create_data_variants(X, y, add_odds=True, balance_data=False)\n    datasets['trainzonder_odds_met_balancing'] = create_data_variants(X, y, add_odds=False, balance_data=True)\n    datasets['trainzonder_odds_zonder_balancing'] = create_data_variants(X, y, add_odds=False, balance_data=False)\n\n    # Scheid de testset in X en y\n    X_test = test_data.drop(columns=[target_column])\n    y_test = test_data[target_column]\n    \n    # Debug: Bekijk de kolomnamen van de testset\n    print(\"Testset kolomnamen:\", X_test.columns.tolist())\n\n    datasets['testmet_odds_met_balancing'] = (X_test.copy(), y_test.copy())  # Testset met odds en met balancing\n    datasets['testmet_odds_zonder_balancing'] = (X_test.copy(), y_test.copy())  # Testset met odds en zonder balancing\n    \n    # Controleer op het bestaan van odds kolommen voordat we ze verwijderen\n    odds_columns = ['B365H', 'B365D', 'B365A']\n    X_test_without_odds = X_test.drop(columns=odds_columns, errors='ignore')  # Verwijder indien aanwezig\n    datasets['testzonder_odds_met_balancing'] = (X_test_without_odds.copy(), y_test.copy())  # Testset zonder odds en met balancing\n    datasets['testzonder_odds_zonder_balancing'] = (X_test_without_odds.copy(), y_test.copy())  # Testset zonder odds en zonder balancing\n\n    return datasets\n\n\ndatasets = prepare_datasets(train_data, test_data)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-26T11:02:16.683021Z","iopub.execute_input":"2024-11-26T11:02:16.683374Z","iopub.status.idle":"2024-11-26T11:02:16.960963Z","shell.execute_reply.started":"2024-11-26T11:02:16.683336Z","shell.execute_reply":"2024-11-26T11:02:16.960012Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\n\n# Stel de stijl in voor een consistente weergave\nsns.set(style=\"whitegrid\")\n\n# Maak de figuur en assen voor de plot\n# Filter de datasets die beginnen met \"test\"\ntrain_datasets = {name: data for name, data in datasets.items() if not name.startswith(\"test\")}\nnum_train_datasets = len(train_datasets)\n\nplt.figure(figsize=(16, 4))  # Pas de grootte aan afhankelijk van het aantal subplots\n\n# Definieer de volgorde van de categorieën en het kleurenpalet\norder = ['H', 'D', 'A']\npalette = 'PuOr'\n\n# Loop door alleen de trainingsdatasets en plot elk in een subplot\nfor i, (name, (X, y)) in enumerate(train_datasets.items()):\n    plt.subplot((num_train_datasets + 1) // 2, 2, i + 1)  # Organiseer in 2 kolommen\n    sns.countplot(x=y, palette=palette, order=order)  # y bevat de 'FTR' target data\n    plt.title(f'Distribution of FTR - {name}', fontsize=14, weight='bold')\n    plt.xlabel('Full Time Result', fontsize=12)\n    plt.ylabel('Frequency', fontsize=12)\n    plt.gca().spines['top'].set_visible(False)\n    plt.gca().spines['right'].set_visible(False)\n\n# Pas layout aan en toon de plot\nplt.tight_layout()\nplt.savefig('countplot_by_FTR.png', format='png', dpi=300)  # Save as high-quality PNG\nplt.show()\n\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-06T14:18:16.229473Z","iopub.execute_input":"2024-11-06T14:18:16.230591Z","iopub.status.idle":"2024-11-06T14:18:17.600492Z","shell.execute_reply.started":"2024-11-06T14:18:16.230543Z","shell.execute_reply":"2024-11-06T14:18:17.599312Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**FEATURE IMPORTANCE**","metadata":{}},{"cell_type":"code","source":"# Functie om feature importances te berekenen met Boruta\ndef analyze_feature_importance(X, y):\n    # Train een Random Forest-model\n    rf = RandomForestClassifier(random_state=42)\n\n    # Gebruik Boruta om de feature importances te bepalen\n    boruta = BorutaPy(\n        estimator=rf,\n        n_estimators='auto',\n        verbose=1,\n        random_state=42\n    )\n\n    # Fit de Boruta op de data\n    boruta.fit(X.values, y.values)\n\n    # Verkrijg de indices van de geselecteerde features\n    ranking = boruta.ranking_\n\n    # Maak een DataFrame voor de importances en rankings\n    importance_df = pd.DataFrame({\n        'Feature': X.columns,\n        'Ranking': ranking\n    })\n\n    # Identificeer goede features\n    good_features = importance_df[importance_df['Ranking'] == 1]['Feature'].tolist()\n\n    return good_features  # Teruggeven van goede features\n\n# Loop door de datasetvarianten en analyseer de feature importances voor elke variant\ngood_features_dict = {}  # Om de goede features per variant op te slaan\nfor variant_name, (X_train, y_train) in datasets.items():\n    if \"test\" not in variant_name:  # Sla testsets over, alleen trainingsets gebruiken\n        print(f\"\\nAnalyzing Feature Importance - {variant_name}\")\n        good_features = analyze_feature_importance(X_train, y_train)\n        good_features_dict[variant_name] = good_features\n\n# Print de goede features per trainingsvariant\nfor variant_name, features in good_features_dict.items():\n    print(f\"\\nGoede Features voor {variant_name}: {features}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-26T10:12:03.297988Z","iopub.execute_input":"2024-11-26T10:12:03.298325Z","iopub.status.idle":"2024-11-26T10:13:35.436716Z","shell.execute_reply.started":"2024-11-26T10:12:03.298294Z","shell.execute_reply":"2024-11-26T10:13:35.435880Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Je hebt de goede features voor elke variant\ngood_features_dict = {\n    'trainmet_odds_met_balancing': ['B365H', 'B365D', 'B365A', 'Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FPG', 'Diff_HPG'],\n    'trainmet_odds_zonder_balancing': ['B365H', 'B365A', 'Diff_S'],\n    'trainzonder_odds_met_balancing': ['Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FTG', 'Diff_FPG', 'Diff_HPG', 'Diff_FRDEF', 'Diff_FRATT'],\n    'trainzonder_odds_zonder_balancing': ['Diff_S', 'Diff_ST', 'Diff_C', 'Diff_FRATT']\n}\n\nfor variant_name, (X, y) in datasets.items():\n    # Controleer of deze variant in de goede features dictionary staat\n    if variant_name in good_features_dict:\n        good_features = good_features_dict[variant_name]\n        \n        # Houd alleen de goede features in de DataFrame\n        X_filtered = X[good_features]\n        \n        # Vervang de originele dataset met de gefilterde dataset\n        datasets[variant_name] = (X_filtered, y)\n\n# Loop door de datasets opnieuw om ook testsets te filteren\nfor variant_name, (X, y) in datasets.items():\n    # Controleer of deze variant een testset is\n    if \"test\" in variant_name:  \n        # Krijg de bijbehorende goede features van de trainingset\n        train_variant_name = variant_name.replace(\"test\", \"train\")\n\n        # Zorg ervoor dat de trainingset in de dictionary bestaat\n        if train_variant_name in good_features_dict:\n            selected_features = good_features_dict[train_variant_name]\n\n            # Controleer of de geselecteerde features in de testset aanwezig zijn\n            common_features = [feature for feature in selected_features if feature in X.columns]\n            if common_features:  # Controleer of er gemeenschappelijke features zijn\n                X_filtered = X[common_features]  # Houd alleen de gemeenschappelijke features\n\n                # Vervang de originele testset in datasets met de nieuwe testset\n                datasets[variant_name] = (X_filtered, y)\n\n# Print de bijgewerkte datasets\nfor variant_name, (X_updated, y_updated) in datasets.items():\n    print(f\"\\nBijgewerkte Dataset - {variant_name}:\")\n    print(X_updated.head())  # Toon de eerste paar rijen van de bijgewerkte dataset\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-26T11:02:27.936011Z","iopub.execute_input":"2024-11-26T11:02:27.936844Z","iopub.status.idle":"2024-11-26T11:02:27.976272Z","shell.execute_reply.started":"2024-11-26T11:02:27.936811Z","shell.execute_reply":"2024-11-26T11:02:27.975441Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**NEEDED PYTROCH**","metadata":{}},{"cell_type":"code","source":"pip install xgboost optuna matplotlib scikit-learn pandas\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T22:20:44.051648Z","iopub.execute_input":"2024-11-21T22:20:44.052049Z","iopub.status.idle":"2024-11-21T22:20:56.834191Z","shell.execute_reply.started":"2024-11-21T22:20:44.052013Z","shell.execute_reply":"2024-11-21T22:20:56.832665Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install torch\n!pip install pytorch-tabnet\n","metadata":{"execution":{"iopub.status.busy":"2024-11-26T10:14:29.353965Z","iopub.execute_input":"2024-11-26T10:14:29.354926Z","iopub.status.idle":"2024-11-26T10:14:46.388507Z","shell.execute_reply.started":"2024-11-26T10:14:29.354869Z","shell.execute_reply":"2024-11-26T10:14:46.387431Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Verwijder alle afbeeldingen met de extensie .png\nfor filename in os.listdir():\n    if filename.endswith(\".png\"):\n        os.remove(filename)\n        print(f\"Deleted: {filename}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-26T10:14:50.926232Z","iopub.execute_input":"2024-11-26T10:14:50.927045Z","iopub.status.idle":"2024-11-26T10:14:50.932713Z","shell.execute_reply.started":"2024-11-26T10:14:50.927008Z","shell.execute_reply":"2024-11-26T10:14:50.931959Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"--> shoutout invoegen naar dat ene Notebook: Gibbons, N. (2021). Tuning TabNet with Optuna [Notebook]. Kaggle. Retrieved from https://www.kaggle.com/code/neilgibbons/tuning-tabnet-with-optuna _-. used for Experiment three","metadata":{}},{"cell_type":"markdown","source":"**MODELS WITH OPTUNA**","metadata":{}},{"cell_type":"code","source":"# Function to calculate profit based on predictions\ndef calculate_profit(y_pred, y_test, odds, stake=1):\n    profit = 0\n    for prediction, actual, odd in zip(y_pred, y_test, odds):\n        if prediction == actual:\n            if prediction == 2:\n                profit += stake * odd[0] - stake  # B365H\n            elif prediction == 1:\n                profit += stake * odd[1] - stake  # B365D\n            elif prediction == 0:\n                profit += stake * odd[2] - stake  # B365A\n        else:\n            profit -= stake\n    return profit\n\n# Dictionary to store results for each dataset variant\nresults_dict = {}\n\n# Function to tune and evaluate RandomForest using Optuna\ndef tune_and_evaluate_rf_optuna(X_train, y_train, X_test, y_test, odds_test):\n    def objective_rf(trial):\n        rf_params = {\n            'n_estimators': trial.suggest_int('n_estimators', 50, 200),  # Number of trees\n            'max_depth': trial.suggest_int('max_depth', 3, 10),  # Maximum depth of trees\n            'min_samples_split': trial.suggest_int('min_samples_split', 2, 11),  # Minimum samples to split\n            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),  # Minimum samples at leaf node\n            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),  # Number of features to consider\n            'bootstrap': trial.suggest_categorical('bootstrap', [True, False])  # Whether to bootstrap samples\n        }\n\n        rf = RandomForestClassifier(random_state=42, **rf_params)\n        pipeline = Pipeline([('rf', rf)])\n\n        # Accuracy as scoring function\n        accuracy_scorer = make_scorer(accuracy_score)\n        scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=accuracy_scorer, n_jobs=-1)\n        \n        return np.mean(scores)\n\n    study_rf = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n    study_rf.optimize(objective_rf, n_trials=30)\n\n    # Best hyperparameters\n    print(\"Best hyperparameters:\", study_rf.best_params)\n\n    # Train model with best parameters\n    best_params = study_rf.best_params\n    rf_tuned = RandomForestClassifier(random_state=42, **best_params)\n    rf_tuned.fit(X_train, y_train)\n    y_pred = rf_tuned.predict(X_test)\n\n    # Evaluate model performance\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Test set accuracy: {accuracy:.4f}\")\n    print(classification_report(y_test, y_pred))\n\n    # Plot confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(\"Confusion Matrix: RandomForest\")\n    plt.show()\n\n    # Calculate profit\n    total_profit = calculate_profit(y_pred, y_test, odds_test)\n\n    return rf_tuned, y_pred\n\n# Loop through the dataset variants\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip test variants\n        continue  \n    \n    print(f\"\\nRunning RF on dataset variant: {variant_name}\")\n\n    # Class distribution in training data\n    print(\"Class distribution in training data:\", Counter(y_train))\n\n    # Determine the appropriate test set based on the training variant\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n        odds_test = X_test[['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    else:\n        print(f\"Variant name {variant_name} does not match any known test set, skipping.\")\n        continue  # If the variant name does not match, skip\n    \n    # Convert DataFrames to NumPy arrays\n    X_train = X_train.values  # Convert training features to NumPy array\n    y_train = y_train.values  # Ensure training labels are in the correct format (NumPy array)\n    X_test = X_test.values  # Convert test features to NumPy array\n    y_test = y_test.values  # Ensure test labels are in the correct format (NumPy array)\n    \n    # Check if test data is valid\n    if X_test is None or y_test is None:\n        print(f\"Test data for {variant_name} is invalid. Skipping.\")\n        continue\n\n    # Train the model with the correct datasets\n    best_model, y_pred = tune_and_evaluate_rf_optuna(X_train, y_train, X_test, y_test, odds_test)\n\n  # List to store individual predictions\n    variant_results = []\n    total_profit = 0\n\n    for i in range(len(y_pred)):\n        match_profit = calculate_profit([y_pred[i]], [y_test[i]], [odds_test[i]])\n        variant_results.append({\n            'Predicted': y_pred[i],\n            'Actual': y_test[i],\n            'B365H': odds_test[i][0],\n            'B365D': odds_test[i][1],\n            'B365A': odds_test[i][2],\n            'Profit': match_profit\n        })\n        total_profit += match_profit\n\n    print(f\"Total profit for {variant_name}: {total_profit}\")\n\n    # Create DataFrame for the current variant and store it in the dictionary\n    results_df = pd.DataFrame(variant_results)\n    results_dict[f\"resultsdf_RF_{variant_name}\"] = results_df\n\n    print(f\"Data for {variant_name} stored as resultsdf_RF_{variant_name}\\n\")\n\n# Display all DataFrames in results_dict if needed\nfor name, df in results_dict.items():\n    print(f\"\\n{name}:\\n\", df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T11:02:41.539117Z","iopub.execute_input":"2024-11-26T11:02:41.539930Z","iopub.status.idle":"2024-11-26T11:04:49.261014Z","shell.execute_reply.started":"2024-11-26T11:02:41.539896Z","shell.execute_reply":"2024-11-26T11:04:49.260172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, make_scorer, classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import cross_val_score\nfrom collections import Counter\n\n# Function to calculate profit based on predictions\ndef calculate_profit(y_pred, y_test, odds, stake=1):\n    profit = 0\n    for prediction, actual, odd in zip(y_pred, y_test, odds):\n        if prediction == actual:\n            if prediction == 2:\n                profit += stake * odd[0] - stake  # B365H\n            elif prediction == 1:\n                profit += stake * odd[1] - stake  # B365D\n            elif prediction == 0:\n                profit += stake * odd[2] - stake  # B365A\n        else:\n            profit -= stake\n    return profit\n\n# Dictionary to store results for each dataset variant\nresults_dict = {}\n\n# Function to tune and evaluate RandomForest using Optuna\ndef tune_and_evaluate_rf_optuna(X_train, y_train, X_test, y_test, odds_test):\n    def objective_rf(trial):\n        rf_params = {\n            'n_estimators': trial.suggest_int('n_estimators', 50, 200),  # Number of trees\n            'max_depth': trial.suggest_int('max_depth', 3, 10),  # Maximum depth of trees\n            'min_samples_split': trial.suggest_int('min_samples_split', 2, 11),  # Minimum samples to split\n            'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10),  # Minimum samples at leaf node\n            'max_features': trial.suggest_categorical('max_features', ['sqrt', 'log2']),  # Number of features to consider\n            'bootstrap': trial.suggest_categorical('bootstrap', [True, False])  # Whether to bootstrap samples\n        }\n\n        rf = RandomForestClassifier(random_state=42, **rf_params)\n        pipeline = Pipeline([('rf', rf)])\n\n        # Accuracy as scoring function\n        accuracy_scorer = make_scorer(accuracy_score)\n        scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=accuracy_scorer, n_jobs=-1)\n        \n        return np.mean(scores)\n\n    study_rf = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n    study_rf.optimize(objective_rf, n_trials=30)\n\n    # Best hyperparameters\n    print(\"Best hyperparameters:\", study_rf.best_params)\n\n    # Train model with best parameters\n    best_params = study_rf.best_params\n    rf_tuned = RandomForestClassifier(random_state=42, **best_params)\n    rf_tuned.fit(X_train, y_train)\n    y_pred = rf_tuned.predict(X_test)\n\n    # Evaluate model performance\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Test set accuracy: {accuracy:.4f}\")\n    print(classification_report(y_test, y_pred))\n\n    # Plot confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(\"Confusion Matrix: Tuned RandomForest\")\n    plt.show()\n\n    # Calculate profit\n    total_profit = calculate_profit(y_pred, y_test, odds_test)\n    print(f\"Total profit: {total_profit}\")\n\n    return rf_tuned, y_pred\n\n# Loop through the dataset variants\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip test variants\n        continue  \n    \n    print(f\"\\nRunning RF on dataset variant: {variant_name}\")\n\n    # Class distribution in training data\n    print(\"Class distribution in training data:\", Counter(y_train))\n\n    # Determine the appropriate test set based on the training variant\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n        odds_test = X_test[['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    else:\n        print(f\"Variant name {variant_name} does not match any known test set, skipping.\")\n        continue  # If the variant name does not match, skip\n    \n    # Convert DataFrames to NumPy arrays\n    X_train = X_train.values  # Convert training features to NumPy array\n    y_train = y_train.values  # Ensure training labels are in the correct format (NumPy array)\n    X_test = X_test.values  # Convert test features to NumPy array\n    y_test = y_test.values  # Ensure test labels are in the correct format (NumPy array)\n    \n    # Check if test data is valid\n    if X_test is None or y_test is None:\n        print(f\"Test data for {variant_name} is invalid. Skipping.\")\n        continue\n\n    # Train the model with the correct datasets\n    best_model, y_pred = tune_and_evaluate_rf_optuna(X_train, y_train, X_test, y_test, odds_test)\n\n  # List to store individual predictions\n    variant_results = []\n    total_profit = 0\n\n    for i in range(len(y_pred)):\n        match_profit = calculate_profit([y_pred[i]], [y_test[i]], [odds_test[i]])\n        variant_results.append({\n            'Predicted': y_pred[i],\n            'Actual': y_test[i],\n            'B365H': odds_test[i][0],\n            'B365D': odds_test[i][1],\n            'B365A': odds_test[i][2],\n            'Profit': match_profit\n        })\n        total_profit += match_profit\n\n    print(f\"Total profit for {variant_name}: {total_profit}\")\n\n    # Create DataFrame for the current variant and store it in the dictionary\n    results_df = pd.DataFrame(variant_results)\n    results_dict[f\"resultsdf_RF_{variant_name}\"] = results_df\n\n    print(f\"Data for {variant_name} stored as resultsdf_RF_{variant_name}\\n\")\n\n# Display all DataFrames in results_dict if needed\nfor name, df in results_dict.items():\n    print(f\"\\n{name}:\\n\", df.head())\n","metadata":{"execution":{"iopub.status.busy":"2024-11-18T14:38:48.052717Z","iopub.execute_input":"2024-11-18T14:38:48.053744Z","iopub.status.idle":"2024-11-18T14:41:41.194402Z","shell.execute_reply.started":"2024-11-18T14:38:48.053681Z","shell.execute_reply":"2024-11-18T14:41:41.193207Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Profit calculation function\ndef calculate_profit(y_pred, y_test, odds, stake=1):\n    profit = 0\n    for prediction, actual, odd in zip(y_pred, y_test, odds):\n        if prediction == actual:\n            if prediction == 2:\n                profit += stake * odd[0] - stake  # B365H\n            elif prediction == 1:\n                profit += stake * odd[1] - stake  # B365D\n            elif prediction == 0:\n                profit += stake * odd[2] - stake  # B365A\n        else:\n            profit -= stake\n    return profit\n\n# Function to tune and evaluate XGBClassifier with Optuna\ndef tune_and_evaluate_xgb_optuna(X_train, y_train, X_test, y_test, odds_test):\n    def objective_xgb(trial):\n        xgb_params = {\n            'n_estimators': trial.suggest_int('n_estimators', 50, 200),  # Number of trees\n            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05),  # Learning rate\n            'max_depth': trial.suggest_int('max_depth', 3, 10),  # Maximum depth of trees\n            'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # Fraction of samples to use in each tree\n            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # Minimum child weight\n            'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # Fraction of samples to use in each tree\n            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)  # Fraction of features for each tree\n        }\n\n        xgb = XGBClassifier(random_state=42, **xgb_params)\n        pipeline = Pipeline([('xgb', xgb)])\n        accuracy_scorer = make_scorer(accuracy_score)\n        scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=accuracy_scorer, n_jobs=-1)\n        return np.mean(scores)\n\n    # Optuna study for hyperparameter optimization\n    study_xgb = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n    study_xgb.optimize(objective_xgb, n_trials=30)\n    \n    # Best hyperparameters\n    print(\"Best hyperparameters:\", study_xgb.best_params)\n\n    # Train model with best parameters\n    best_params = study_xgb.best_params\n    xgb_tuned = XGBClassifier(random_state=42, **best_params)\n    xgb_tuned.fit(X_train, y_train)\n    y_pred = xgb_tuned.predict(X_test)\n\n    # Evaluate model performance\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Test set accuracy: {accuracy:.4f}\")\n    print(classification_report(y_test, y_pred))\n\n    # Plot confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(\"Confusion Matrix: XGBoost\")\n    plt.show()\n\n    # Calculate profit\n    total_profit = calculate_profit(y_pred, y_test, odds_test)\n\n    return xgb_tuned, y_pred\n\nresults_dict = {}\n\n# Run the tuning and evaluation for each dataset variant\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:\n        continue  \n\n    print(f\"\\nRunning XGBoost on dataset variant: {variant_name}\")\n\n    # Select appropriate test set\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n        odds_test = X_test[['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    else:\n        print(f\"Unknown variant name {variant_name}, skipping.\")\n        continue\n\n    # Convert data to arrays\n    X_train = X_train.values\n    y_train = y_train.values\n    X_test = X_test.values\n    y_test = y_test.values\n\n    best_model, y_pred = tune_and_evaluate_xgb_optuna(X_train, y_train, X_test, y_test, odds_test)\n\n    variant_results = []\n    total_profit = 0\n\n    for i in range(len(y_pred)):\n        match_profit = calculate_profit([y_pred[i]], [y_test[i]], [odds_test[i]])\n        variant_results.append({\n            'Predicted': y_pred[i],\n            'Actual': y_test[i],\n            'B365H': odds_test[i][0],\n            'B365D': odds_test[i][1],\n            'B365A': odds_test[i][2],\n            'Profit': match_profit\n        })\n        total_profit += match_profit\n\n    print(f\"Total profit for {variant_name}: {total_profit}\")\n\n    # Create DataFrame for the current variant and store it in the dictionary\n    results_df = pd.DataFrame(variant_results)\n    results_dict[f\"resultsdf_RF_{variant_name}\"] = results_df\n\n    print(f\"Data for {variant_name} stored as resultsdf_RF_{variant_name}\\n\")\n\n# Display all DataFrames in results_dict if needed\nfor name, df in results_dict.items():\n    print(f\"\\n{name}:\\n\", df.head())\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T11:05:08.044017Z","iopub.execute_input":"2024-11-26T11:05:08.044383Z","iopub.status.idle":"2024-11-26T11:06:55.376007Z","shell.execute_reply.started":"2024-11-26T11:05:08.044350Z","shell.execute_reply":"2024-11-26T11:06:55.375004Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import optuna\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import accuracy_score, make_scorer, classification_report, confusion_matrix, ConfusionMatrixDisplay\nfrom sklearn.model_selection import cross_val_score\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\n# Profit calculation function\ndef calculate_profit(y_pred, y_test, odds, stake=1):\n    profit = 0\n    for prediction, actual, odd in zip(y_pred, y_test, odds):\n        if prediction == actual:\n            if prediction == 2:\n                profit += stake * odd[0] - stake  # B365H\n            elif prediction == 1:\n                profit += stake * odd[1] - stake  # B365D\n            elif prediction == 0:\n                profit += stake * odd[2] - stake  # B365A\n        else:\n            profit -= stake\n    return profit\n\n# Function to tune and evaluate XGBClassifier with Optuna\ndef tune_and_evaluate_xgb_optuna(X_train, y_train, X_test, y_test, odds_test):\n    def objective_xgb(trial):\n        xgb_params = {\n            'n_estimators': trial.suggest_int('n_estimators', 50, 200),  # Number of trees\n            'learning_rate': trial.suggest_float('learning_rate', 0.001, 0.05),  # Learning rate\n            'max_depth': trial.suggest_int('max_depth', 3, 10),  # Maximum depth of trees\n            'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # Fraction of samples to use in each tree\n            'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),  # Minimum child weight\n            'subsample': trial.suggest_float('subsample', 0.5, 1.0),  # Fraction of samples to use in each tree\n            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0)  # Fraction of features for each tree\n        }\n\n        xgb = XGBClassifier(random_state=42, **xgb_params)\n        pipeline = Pipeline([('xgb', xgb)])\n        accuracy_scorer = make_scorer(accuracy_score)\n        scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring=accuracy_scorer, n_jobs=-1)\n        return np.mean(scores)\n\n    # Optuna study for hyperparameter optimization\n    study_xgb = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=42))\n    study_xgb.optimize(objective_xgb, n_trials=30)\n    \n    # Best hyperparameters\n    print(\"Best hyperparameters:\", study_xgb.best_params)\n\n    # Train model with best parameters\n    best_params = study_xgb.best_params\n    xgb_tuned = XGBClassifier(random_state=42, **best_params)\n    xgb_tuned.fit(X_train, y_train)\n    y_pred = xgb_tuned.predict(X_test)\n\n    # Evaluate model performance\n    accuracy = accuracy_score(y_test, y_pred)\n    print(f\"Test set accuracy: {accuracy:.4f}\")\n    print(classification_report(y_test, y_pred))\n\n    # Plot confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(\"Confusion Matrix: Tuned XGBoost\")\n    plt.show()\n\n    # Calculate profit\n    total_profit = calculate_profit(y_pred, y_test, odds_test)\n    print(f\"Total profit: {total_profit}\")\n\n    return xgb_tuned, y_pred\n\nresults_dict = {}\n\n# Run the tuning and evaluation for each dataset variant\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:\n        continue  \n\n    print(f\"\\nRunning XGBoost on dataset variant: {variant_name}\")\n\n    # Select appropriate test set\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n        odds_test = X_test[['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    else:\n        print(f\"Unknown variant name {variant_name}, skipping.\")\n        continue\n\n    # Convert data to arrays\n    X_train = X_train.values\n    y_train = y_train.values\n    X_test = X_test.values\n    y_test = y_test.values\n\n    best_model, y_pred = tune_and_evaluate_xgb_optuna(X_train, y_train, X_test, y_test, odds_test)\n\n    # Store results\n    results_dict[f\"results_XGB_{variant_name}\"] = pd.DataFrame({\n        'Predicted': y_pred,\n        'Actual': y_test,\n        'Profit': [calculate_profit([pred], [act], [odds]) for pred, act, odds in zip(y_pred, y_test, odds_test)]\n    })\n\n# Display results\nfor name, df in results_dict.items():\n    print(f\"\\n{name}:\\n\", df.head())\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-19T10:46:35.648981Z","iopub.execute_input":"2024-11-19T10:46:35.649407Z","iopub.status.idle":"2024-11-19T10:48:57.233218Z","shell.execute_reply.started":"2024-11-19T10:46:35.649372Z","shell.execute_reply":"2024-11-19T10:48:57.232039Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stel de random seed in voor consistentie\nSEED = 42  # Kies een vaste seed voor consistentie\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndef evaluate(y_true, y_pred, model_name):\n    accuracy = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred, average='macro')\n    print(f\"{model_name} - Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}\")\n\ndef calculate_profit(y_pred, y_test, odds, stake=1):\n    profit = 0\n    for prediction, actual, odd in zip(y_pred, y_test, odds):\n        if prediction == actual:\n            if prediction == 2:\n                profit += stake * odd[0] - stake  # B365H\n            elif prediction == 1:\n                profit += stake * odd[1] - stake  # B365D\n            elif prediction == 0:\n                profit += stake * odd[2] - stake  # B365A\n        else:\n            profit -= stake\n    return profit\n\ndef tune_and_evaluate_tabnet(X_train, y_train, X_test, y_test, odds_test):\n      \n    def Objective_tabnet(trial):\n        mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n        n_da = trial.suggest_int(\"n_da\", 8, 32, step=8)\n        n_steps = trial.suggest_int(\"n_steps\", 3, 10, step=1)\n        gamma = trial.suggest_float(\"gamma\", 0.01, 0.2, step=0.01)\n        n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n        lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n\n        optimizer_params = dict(lr=2e-2, weight_decay=1e-5)\n        tabnet_params = dict(\n            n_d=n_da, \n            n_a=n_da, \n            n_steps=n_steps, \n            gamma=gamma,\n            lambda_sparse=lambda_sparse, \n            optimizer_fn=torch.optim.Adam,\n            optimizer_params=optimizer_params, \n            mask_type=mask_type,\n            n_shared=n_shared,\n            scheduler_params=dict(\n                patience=trial.suggest_int(\"patienceScheduler\", low=5, high=10),\n                min_lr=1e-5,\n                factor=0.5,\n            ),\n            scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n            verbose=0,\n            seed=SEED  # Seed toegevoegd aan TabNet\n        )\n\n        clf_tab_opt = TabNetClassifier(**tabnet_params, device_name='cuda' if torch.cuda.is_available() else 'cpu')\n        \n        # Cross-validation met accuracy als scoring functie\n        accuracy_scorer = make_scorer(accuracy_score)  # Gebruik accuracy in plaats van F1-score\n        scores = cross_val_score(\n            clf_tab_opt, \n            X_train,\n            y_train, \n            cv=5, \n            scoring=accuracy_scorer, \n            fit_params={\n                'eval_set': [(X_train, y_train)],\n                'max_epochs': trial.suggest_int(\"max_epochs\", 10, 50),\n                'patience': trial.suggest_int(\"patience\", low=5, high=10),\n                'batch_size': 64\n            }\n        )\n        \n        # Gemiddelde accuracy berekenen\n        accuracy = np.mean(scores)\n        return accuracy\n\n    # Optuna logging en study instellen met vaste seed\n    optuna.logging.set_verbosity(optuna.logging.DEBUG)\n    study_tabnet = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=SEED))  # Seed voor Optuna\n    study_tabnet.optimize(Objective_tabnet, n_trials=30)\n\n    # Beste parameters opslaan\n    TabNet_params = study_tabnet.best_params\n    print(\"Best parameters:\", TabNet_params)\n\n    # Definitieve TabNet model parameters\n    final_params_tab = dict(\n        n_d=TabNet_params['n_da'], \n        n_a=TabNet_params['n_da'], \n        n_steps=TabNet_params['n_steps'], \n        gamma=TabNet_params['gamma'],\n        lambda_sparse=TabNet_params['lambda_sparse'], \n        optimizer_fn=torch.optim.Adam,\n        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n        mask_type=TabNet_params['mask_type'], \n        n_shared=TabNet_params['n_shared'],\n        scheduler_params=dict(\n            patience=TabNet_params['patienceScheduler'],\n            min_lr=1e-5,\n            factor=0.5,\n        ),\n        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n        verbose=0,\n        seed=SEED  # Seed toegevoegd aan definitief TabNet model\n    )\n\n    # Train het beste model en evalueer\n    epochs = TabNet_params['max_epochs']\n    clf_tuned_tab = TabNetClassifier(**final_params_tab, device_name='cuda' if torch.cuda.is_available() else 'cpu')\n    clf_tuned_tab.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        max_epochs=epochs,\n        patience=TabNet_params['patience'],\n        batch_size=64\n    )\n\n    # Voorspellingen en evaluatie\n    y_pred_tabnet = clf_tuned_tab.predict(X_test)\n\n    # Evaluatie en metrics\n    evaluate(y_test, y_pred_tabnet, \"TabNet\")\n\n    # Confusion Matrix en classification report\n    cm = confusion_matrix(y_test, y_pred_tabnet)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(\"Confusion Matrix: TabNet\")\n    plt.show()\n\n    class_names = [\"class_1\", \"class_2\", \"class_3\"]\n    print(classification_report(y_test, y_pred_tabnet, target_names=class_names))\n\n    # Model opslaan\n    torch.save(clf_tuned_tab, 'tabnet_model.pth')\n    print(\"Model saved as 'tabnet_model.pth'\")\n\n    return clf_tuned_tab, y_pred_tabnet  # Teruggeven van model en voorspellingen\n\n# Dictionary to store results for each dataset variant\nresults_dict = {}\n\n# Loop through the dataset variants\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip test variants\n        continue  \n    \n    print(f\"\\nRunning TabNet on dataset variant: {variant_name}\")\n\n    # Class distribution in training data\n    print(\"Class distribution in training data:\", Counter(y_train))\n\n    # Determine the appropriate test set based on the training variant\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n        odds_test = X_test[['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    else:\n        print(f\"Variant name {variant_name} does not match any known test set, skipping.\")\n        continue  # If the variant name does not match, skip\n    \n    # Convert DataFrames to NumPy arrays\n    X_train = X_train.values  # Convert training features to NumPy array\n    y_train = y_train.values  # Ensure training labels are in the correct format (NumPy array)\n    X_test = X_test.values  # Convert test features to NumPy array\n    y_test = y_test.values  # Ensure test labels are in the correct format (NumPy array)\n    \n    # Check if test data is valid\n    if X_test is None or y_test is None:\n        print(f\"Test data for {variant_name} is invalid. Skipping.\")\n        continue\n\n    # Train the model with the correct datasets\n    best_model, y_pred = tune_and_evaluate_tabnet(X_train, y_train, X_test, y_test, odds_test)\n\n    # List to store individual predictions\n    variant_results = []\n    total_profit = 0\n\n    for i in range(len(y_pred)):\n        match_profit = calculate_profit([y_pred[i]], [y_test[i]], [odds_test[i]])\n        variant_results.append({\n            'Predicted': y_pred[i],\n            'Actual': y_test[i],\n            'B365H': odds_test[i][0],\n            'B365D': odds_test[i][1],\n            'B365A': odds_test[i][2],\n            'Profit': match_profit\n        })\n        total_profit += match_profit\n\n    print(f\"Total profit for {variant_name}: {total_profit}\")\n\n    # Create DataFrame for the current variant and store it in the dictionary\n    results_df = pd.DataFrame(variant_results)\n    results_dict[f\"resultsdf_RF_{variant_name}\"] = results_df\n\n    print(f\"Data for {variant_name} stored as resultsdf_RF_{variant_name}\\n\")\n\n# Display all DataFrames in results_dict if needed\nfor name, df in results_dict.items():\n    print(f\"\\n{name}:\\n\", df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T11:08:36.683090Z","iopub.execute_input":"2024-11-26T11:08:36.683621Z","iopub.status.idle":"2024-11-26T18:34:37.516234Z","shell.execute_reply.started":"2024-11-26T11:08:36.683589Z","shell.execute_reply":"2024-11-26T18:34:37.515499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#CV-5 + N-trails = 30!\nimport numpy as np\nimport torch\nfrom sklearn.decomposition import PCA\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import make_scorer, f1_score, accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport optuna\nimport optuna.visualization.matplotlib as optuna_vis\nimport matplotlib.pyplot as plt\nfrom collections import Counter\n\n# Stel de random seed in voor consistentie\nSEED = 42  # Kies een vaste seed voor consistentie\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\ndef evaluate(y_true, y_pred, model_name):\n    accuracy = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred, average='macro')\n    print(f\"{model_name} - Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}\")\n\ndef calculate_profit(y_pred, y_test, odds, stake=1):\n    profit = 0\n    for prediction, actual, odd in zip(y_pred, y_test, odds):\n        if prediction == actual:\n            if prediction == 2:\n                profit += stake * odd[0] - stake  # B365H\n            elif prediction == 1:\n                profit += stake * odd[1] - stake  # B365D\n            elif prediction == 0:\n                profit += stake * odd[2] - stake  # B365A\n        else:\n            profit -= stake\n    return profit\n\ndef tune_and_evaluate_tabnet(X_train, y_train, X_test, y_test, odds_test):\n    \"\"\"Train and evaluate the TabNet model without PCA.\"\"\"\n    \n    def Objective_tabnet(trial):\n        mask_type = trial.suggest_categorical(\"mask_type\", [\"entmax\", \"sparsemax\"])\n        n_da = trial.suggest_int(\"n_da\", 8, 32, step=8)\n        n_steps = trial.suggest_int(\"n_steps\", 3, 10, step=1)\n        gamma = trial.suggest_float(\"gamma\", 0.01, 0.2, step=0.01)\n        n_shared = trial.suggest_int(\"n_shared\", 1, 3)\n        lambda_sparse = trial.suggest_float(\"lambda_sparse\", 1e-6, 1e-3, log=True)\n\n        optimizer_params = dict(lr=2e-2, weight_decay=1e-5)\n        tabnet_params = dict(\n            n_d=n_da, \n            n_a=n_da, \n            n_steps=n_steps, \n            gamma=gamma,\n            lambda_sparse=lambda_sparse, \n            optimizer_fn=torch.optim.Adam,\n            optimizer_params=optimizer_params, \n            mask_type=mask_type,\n            n_shared=n_shared,\n            scheduler_params=dict(\n                patience=trial.suggest_int(\"patienceScheduler\", low=5, high=10),\n                min_lr=1e-5,\n                factor=0.5,\n            ),\n            scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n            verbose=0,\n            seed=SEED  # Seed toegevoegd aan TabNet\n        )\n\n        clf_tab_opt = TabNetClassifier(**tabnet_params, device_name='cuda' if torch.cuda.is_available() else 'cpu')\n        \n        # Cross-validation met accuracy als scoring functie\n        accuracy_scorer = make_scorer(accuracy_score)  # Gebruik accuracy in plaats van F1-score\n        scores = cross_val_score(\n            clf_tab_opt, \n            X_train,\n            y_train, \n            cv=5, \n            scoring=accuracy_scorer, \n            fit_params={\n                'eval_set': [(X_train, y_train)],\n                'max_epochs': trial.suggest_int(\"max_epochs\", 10, 50),\n                'patience': trial.suggest_int(\"patience\", low=5, high=10),\n                'batch_size': 64\n            }\n        )\n        \n        # Gemiddelde accuracy berekenen\n        accuracy = np.mean(scores)\n        return accuracy\n\n    # Optuna logging en study instellen met vaste seed\n    optuna.logging.set_verbosity(optuna.logging.DEBUG)\n    study_tabnet = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=SEED))  # Seed voor Optuna\n    study_tabnet.optimize(Objective_tabnet, n_trials=30)\n\n    # Beste parameters opslaan\n    TabNet_params = study_tabnet.best_params\n    print(\"Best parameters:\", TabNet_params)\n\n    # Definitieve TabNet model parameters\n    final_params_tab = dict(\n        n_d=TabNet_params['n_da'], \n        n_a=TabNet_params['n_da'], \n        n_steps=TabNet_params['n_steps'], \n        gamma=TabNet_params['gamma'],\n        lambda_sparse=TabNet_params['lambda_sparse'], \n        optimizer_fn=torch.optim.Adam,\n        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n        mask_type=TabNet_params['mask_type'], \n        n_shared=TabNet_params['n_shared'],\n        scheduler_params=dict(\n            patience=TabNet_params['patienceScheduler'],\n            min_lr=1e-5,\n            factor=0.5,\n        ),\n        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n        verbose=0,\n        seed=SEED  # Seed toegevoegd aan definitief TabNet model\n    )\n\n    # Train het beste model en evalueer\n    epochs = TabNet_params['max_epochs']\n    clf_tuned_tab = TabNetClassifier(**final_params_tab, device_name='cuda' if torch.cuda.is_available() else 'cpu')\n    clf_tuned_tab.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        max_epochs=epochs,\n        patience=TabNet_params['patience'],\n        batch_size=64\n    )\n\n    # Voorspellingen en evaluatie\n    y_pred_tabnet = clf_tuned_tab.predict(X_test)\n\n    # Evaluatie en metrics\n    evaluate(y_test, y_pred_tabnet, \"Tuned TabNet without PCA\")\n\n    # Confusion Matrix en classification report\n    cm = confusion_matrix(y_test, y_pred_tabnet)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(\"Confusion Matrix: Tuned TabNet without PCA\")\n    plt.show()\n\n    class_names = [\"class_1\", \"class_2\", \"class_3\"]\n    print(classification_report(y_test, y_pred_tabnet, target_names=class_names))\n\n    # Model opslaan\n    torch.save(clf_tuned_tab, 'tuned_tabnet_model_without_pca.pth')\n    print(\"Model saved as 'tuned_tabnet_model_without_pca.pth'\")\n\n    return clf_tuned_tab, y_pred_tabnet  # Teruggeven van model en voorspellingen\n\n# Dictionary to store results for each dataset variant\nresults_dict = {}\n\n# Loop through the dataset variants\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip test variants\n        continue  \n    \n    print(f\"\\nRunning TabNet on dataset variant: {variant_name}\")\n\n    # Class distribution in training data\n    print(\"Class distribution in training data:\", Counter(y_train))\n\n    # Determine the appropriate test set based on the training variant\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n        odds_test = X_test[['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n        odds_test = datasets['testmet_odds_met_balancing'][0][['B365H', 'B365D', 'B365A']].values\n    else:\n        print(f\"Variant name {variant_name} does not match any known test set, skipping.\")\n        continue  # If the variant name does not match, skip\n    \n    # Convert DataFrames to NumPy arrays\n    X_train = X_train.values  # Convert training features to NumPy array\n    y_train = y_train.values  # Ensure training labels are in the correct format (NumPy array)\n    X_test = X_test.values  # Convert test features to NumPy array\n    y_test = y_test.values  # Ensure test labels are in the correct format (NumPy array)\n    \n    # Check if test data is valid\n    if X_test is None or y_test is None:\n        print(f\"Test data for {variant_name} is invalid. Skipping.\")\n        continue\n\n    # Train the model with the correct datasets\n    best_model, y_pred = tune_and_evaluate_tabnet(X_train, y_train, X_test, y_test, odds_test)\n\n    # List to store individual predictions\n    variant_results = []\n    total_profit = 0\n\n    for i in range(len(y_pred)):\n        match_profit = calculate_profit([y_pred[i]], [y_test[i]], [odds_test[i]])\n        variant_results.append({\n            'Predicted': y_pred[i],\n            'Actual': y_test[i],\n            'B365H': odds_test[i][0],\n            'B365D': odds_test[i][1],\n            'B365A': odds_test[i][2],\n            'Profit': match_profit\n        })\n        total_profit += match_profit\n\n    print(f\"Total profit for {variant_name}: {total_profit}\")\n\n    # Create DataFrame for the current variant and store it in the dictionary\n    results_df = pd.DataFrame(variant_results)\n    results_dict[f\"resultsdf_RF_{variant_name}\"] = results_df\n\n    print(f\"Data for {variant_name} stored as resultsdf_RF_{variant_name}\\n\")\n\n# Display all DataFrames in results_dict if needed\nfor name, df in results_dict.items():\n    print(f\"\\n{name}:\\n\", df.head())","metadata":{"execution":{"iopub.status.busy":"2024-11-08T14:57:15.858993Z","iopub.execute_input":"2024-11-08T14:57:15.859452Z","iopub.status.idle":"2024-11-08T23:07:59.344147Z","shell.execute_reply.started":"2024-11-08T14:57:15.859409Z","shell.execute_reply":"2024-11-08T23:07:59.343208Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Verwijder alle afbeeldingen met de extensie .png\nfor filename in os.listdir():\n    if filename.endswith(\".png\"):\n        os.remove(filename)\n        print(f\"Deleted: {filename}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T22:48:17.048492Z","iopub.execute_input":"2024-11-21T22:48:17.049170Z","iopub.status.idle":"2024-11-21T22:48:17.055216Z","shell.execute_reply.started":"2024-11-21T22:48:17.049136Z","shell.execute_reply":"2024-11-21T22:48:17.054374Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport numpy as np\n\nfeature_names_dict = {\n    'trainmet_odds_met_balancing': ['B365H', 'B365D', 'B365A', 'Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FPG', 'Diff_HPG'],\n    'trainmet_odds_zonder_balancing': ['B365H', 'B365A', 'Diff_S'],\n    'trainzonder_odds_met_balancing': ['Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FTG', 'Diff_FPG', 'Diff_HPG', 'Diff_FRDEF', 'Diff_FRATT'],\n    'trainzonder_odds_zonder_balancing': ['Diff_S', 'Diff_ST', 'Diff_C', 'Diff_FRATT']\n}\n\n# Hyperparameters voor elk model\npredefined_hyperparameters = {\n    'trainmet_odds_met_balancing': {'n_estimators': 166, 'max_depth': 5, 'min_samples_split': 7,\n                                    'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True},\n    'trainmet_odds_zonder_balancing': {'n_estimators': 166, 'max_depth': 5, 'min_samples_split': 7,\n                                       'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True},\n    'trainzonder_odds_met_balancing': {'n_estimators': 196, 'max_depth': 10, 'min_samples_split': 6,\n                                       'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False},\n    'trainzonder_odds_zonder_balancing': {'n_estimators': 187, 'max_depth': 3, 'min_samples_split': 5,\n                                          'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}\n}\n\n# Functie om de SHAP summary plot voor Class 1 te verbeteren\ndef generate_class1_summary_plot(model, X_test, feature_names, variant_name):\n    # Maak een SHAP explainer\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X_test)\n    \n    # Bereken gemiddelde absolute SHAP-waarden voor Class 1\n    mean_shap_values_class1 = np.abs(shap_values[1]).mean(axis=0)\n    \n    # Stel figuurgrootte in voor een consistente breedte en hoogte\n    plt.figure(figsize=(9, 6))  # Pas de grootte aan voor de grafiek\n    \n    # Maak de balkgrafiek\n    plt.barh(feature_names, mean_shap_values_class1, color='purple')\n    \n    # Zet de belangrijkste feature bovenaan\n    plt.gca().invert_yaxis()  # Om de belangrijkste feature bovenaan te zetten\n    \n    # Pas de stijl van de grafiek aan:\n    plt.xlabel(\"Mean(|SHAP value|) (Impact on Model Output Magnitude)\", fontsize=12)\n    plt.title(f\"SHAP Summary (Class 1) - {variant_name}\", fontsize=14)\n    \n    # Verberg de grid en verbeter de layout\n    plt.grid(False)  # Verwijder de grid\n    plt.gca().spines['top'].set_visible(False)  # Verberg bovenste randlijn\n    plt.gca().spines['right'].set_visible(False)  # Verberg rechter randlijn\n    plt.gca().spines['left'].set_visible(True)  # Laat linker randlijn staan (voor de y-as)\n    plt.gca().spines['bottom'].set_visible(True)  # Laat onderrandlijn staan (voor de x-as)\n    \n    # Toon de grafiek\n    plt.show()  # Toon de grafiek\n    plt.savefig(f\"RFshap_summary_bar_class1_{variant_name}.png\", bbox_inches='tight')  # Sla de grafiek op met hoge resolutie\n    plt.close()\n\n# Functie om SHAP-plots te genereren en op te slaan\ndef generate_and_save_shap_plots(model, X_test, feature_names, variant_name):\n    # Maak een SHAP explainer\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X_test)\n    \n    # 1. Standaard SHAP-summary-plot\n    plt.figure(figsize=(12, 6))  # Stel figuurgrootte in\n    shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)\n    plt.title(f\"SHAP Summary Plot - {variant_name}\")\n    plt.show()\n    plt.savefig(f\"RF_shap_summary - {variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n    # 2. SHAP-summary-plot specifiek voor shap_values[1]\n    plt.figure(figsize=(12, 6))  # Stel figuurgrootte in\n    shap.summary_plot(shap_values[1], X_test, feature_names=feature_names, show=False)\n    plt.title(f\"SHAP Summary (Class 1)_{variant_name}\")\n    plt.show()\n    plt.savefig(f\"RFshap_summary_class1_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n# Functie om een model te trainen en alle plots te genereren\ndef train_and_generate_plots(X_train, y_train, X_test, y_test, variant_name):\n    # Haal de hyperparameters op\n    rf_params = predefined_hyperparameters[variant_name]\n    \n    # Train het model\n    model = RandomForestClassifier(random_state=42, **rf_params)\n    model.fit(X_train, y_train)\n    \n    # Haal de juiste feature-namen op\n    feature_names = feature_names_dict[variant_name]\n    \n    # Genereer SHAP-plots\n    generate_and_save_shap_plots(model, X_test, feature_names, variant_name)\n    \n    # Genereer de specifieke balkgrafiek voor Class 1\n    generate_class1_summary_plot(model, X_test, feature_names, variant_name)\n    \n    # Voorspelling en evaluatie\n    y_pred = model.predict(X_test)\n    print(f\"Results for {variant_name}:\")\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n    print(classification_report(y_test, y_pred))\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(f\"Confusion Matrix RF {variant_name}\")\n    plt.savefig(f\"RFconfusion_matrix_{variant_name}.png\", bbox_inches='tight')\n    plt.show()\n    plt.close()\n\n# Data preparation en model training per variant\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip test sets in training loop\n        continue\n    \n    print(f\"\\nRunning RF on dataset variant: {variant_name}\")\n\n    # Selecteer bijbehorende testdataset\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test, y_test = datasets['testmet_odds_met_balancing']\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test, y_test = datasets['testmet_odds_zonder_balancing']\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test, y_test = datasets['testzonder_odds_met_balancing']\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test, y_test = datasets['testzonder_odds_zonder_balancing']\n    else:\n        print(f\"Variant {variant_name} heeft geen bijbehorende testset. Skipping.\")\n        continue\n\n    # Zorg ervoor dat dataframes geschikt zijn\n    X_train = pd.DataFrame(X_train) if isinstance(X_train, pd.DataFrame) else pd.DataFrame(X_train, columns=feature_names_dict[variant_name])\n    X_test = pd.DataFrame(X_test) if isinstance(X_test, pd.DataFrame) else pd.DataFrame(X_test, columns=feature_names_dict[variant_name])\n    \n    # Train het model en genereer SHAP-visualisaties\n    train_and_generate_plots(X_train, y_train, X_test, y_test, variant_name)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T22:47:17.712454Z","iopub.execute_input":"2024-11-21T22:47:17.712841Z","iopub.status.idle":"2024-11-21T22:47:36.818628Z","shell.execute_reply.started":"2024-11-21T22:47:17.712809Z","shell.execute_reply":"2024-11-21T22:47:36.817751Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"feature_names_dict = {\n    'trainmet_odds_met_balancing': ['B365H', 'B365D', 'B365A', 'Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FPG', 'Diff_HPG'],\n    'trainmet_odds_zonder_balancing': ['B365H', 'B365A', 'Diff_S'],\n    'trainzonder_odds_met_balancing': ['Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FTG', 'Diff_FPG', 'Diff_HPG', 'Diff_FRDEF', 'Diff_FRATT'],\n    'trainzonder_odds_zonder_balancing': ['Diff_S', 'Diff_ST', 'Diff_C', 'Diff_FRATT']\n}\n\n# Hyperparameters voor RandomForest-model\npredefined_hyperparameters = {\n    'trainmet_odds_met_balancing': {'n_estimators': 166, 'max_depth': 5, 'min_samples_split': 7,\n                                    'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True},\n    'trainmet_odds_zonder_balancing': {'n_estimators': 166, 'max_depth': 5, 'min_samples_split': 7,\n                                       'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True},\n    'trainzonder_odds_met_balancing': {'n_estimators': 196, 'max_depth': 10, 'min_samples_split': 6,\n                                       'min_samples_leaf': 1, 'max_features': 'log2', 'bootstrap': False},\n    'trainzonder_odds_zonder_balancing': {'n_estimators': 187, 'max_depth': 3, 'min_samples_split': 5,\n                                          'min_samples_leaf': 3, 'max_features': 'log2', 'bootstrap': True}\n}\n# Mapping van variant_names naar beschrijvingen\nvariant_name_mapping = {\n    'trainmet_odds_met_balancing': 'C1',\n    'trainmet_odds_zonder_balancing': 'C2',\n    'trainzonder_odds_met_balancing': 'C3',\n    'trainzonder_odds_zonder_balancing': 'C4'\n}\n\n\n# Functie om feature importance plot voor Random Forest te genereren\ndef generate_feature_importance_plot_rf(model, feature_names, variant_name):\n    plt.figure(figsize=(8, 6))\n    \n    # Haal de feature importances op\n    importances = model.feature_importances_\n    \n    # Sorteer de importances in dalende volgorde\n    indices = importances.argsort()[::1]\n    \n    plt.yticks(range(len(indices)), [feature_names[i] for i in indices], rotation=0, ha=\"right\", fontsize=10)\n    # Maak de grafiek\n    importance = plt.barh(range(len(indices)), importances[indices], align=\"center\", color='teal')\n    \n    plt.xlim(0, 0.50)\n    plt.xticks([i * 0.10 for i in range(6)], fontsize=10)  \n    \n    # Verwijder de rasterlijnen\n    plt.grid(False)\n    \n    for i, value in enumerate(importances[indices]):\n        plt.text(value + 0.01, i, f\"{value:.2f}\", va='center', fontsize=9, color='black')\n    \n    # Verwijder de bovenste en rechter grafieklijnen\n    plt.gca().spines['top'].set_visible(False)\n    plt.gca().spines['right'].set_visible(False)\n    \n    # Grafiektitel en labels\n    plt.title(f\"Feature Importance - Random Forest\", fontsize=14)\n    plt.xlabel(\"Importance\", fontsize=12)\n    plt.ylabel(\"Feature\", fontsize=12)\n    \n    plt.tight_layout()\n    plt.savefig(f\"RF_Feature_Importance_{variant_name}.png\", bbox_inches='tight')\n    plt.show()\n    plt.close()\n    \n# Functie om een Random Forest-model te trainen en de feature importance plot te genereren\ndef train_and_generate_plots_rf(X_train, y_train, X_test, y_test, variant_name):\n    # Haal de hyperparameters op\n    rf_params = predefined_hyperparameters[variant_name]\n    \n    # Train het model\n    model = RandomForestClassifier(random_state=42, **rf_params)\n    model.fit(X_train, y_train)\n    \n    # Haal de juiste feature-namen op\n    feature_names = feature_names_dict[variant_name]\n\n    readable_name = variant_name_mapping.get(variant_name, variant_name)\n    \n    # Genereer de Random Forest Feature Importance Plot\n    generate_feature_importance_plot_rf(model, feature_names, variant_name)\n    \n    # Voorspelling en evaluatie\n    y_pred = model.predict(X_test)\n    print(f\"Results for {variant_name}:\")\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n    print(classification_report(y_test, y_pred))\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(f\"Confusion Matrix Random Forest - {readable_name}\")\n    plt.savefig(f\"RF_confusion_matrix_{variant_name}.png\", bbox_inches='tight')\n    plt.show()\n    plt.close()\n\n# Data preparation en model training per variant\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip test sets in training loop\n        continue\n    \n    print(f\"\\nRunning Random Forest on dataset variant: {variant_name}\")\n\n    # Selecteer bijbehorende testdataset\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test, y_test = datasets['testmet_odds_met_balancing']\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test, y_test = datasets['testmet_odds_zonder_balancing']\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test, y_test = datasets['testzonder_odds_met_balancing']\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test, y_test = datasets['testzonder_odds_zonder_balancing']\n    else:\n        print(f\"Variant {variant_name} heeft geen bijbehorende testset. Skipping.\")\n        continue\n\n    # Zorg ervoor dat dataframes geschikt zijn\n    X_train = pd.DataFrame(X_train) if isinstance(X_train, pd.DataFrame) else pd.DataFrame(X_train, columns=feature_names_dict[variant_name])\n    X_test = pd.DataFrame(X_test) if isinstance(X_test, pd.DataFrame) else pd.DataFrame(X_test, columns=feature_names_dict[variant_name])\n    \n    # Train het model en genereer plots\n    train_and_generate_plots_rf(X_train, y_train, X_test, y_test, variant_name)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-26T10:46:46.657494Z","iopub.execute_input":"2024-11-26T10:46:46.657827Z","iopub.status.idle":"2024-11-26T10:46:52.268083Z","shell.execute_reply.started":"2024-11-26T10:46:46.657800Z","shell.execute_reply":"2024-11-26T10:46:52.267289Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"variant_name_mapping = {\n    'trainmet_odds_met_balancing': 'C1',\n    'trainmet_odds_zonder_balancing': 'C2',\n    'trainzonder_odds_met_balancing': 'C3',\n    'trainzonder_odds_zonder_balancing': 'C4'\n}\n\n# Handmatig ingestelde feature-namen per dataset\nfeature_names_dict = {\n    'trainmet_odds_met_balancing': ['B365H', 'B365D', 'B365A', 'Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FPG', 'Diff_HPG'],\n    'trainmet_odds_zonder_balancing': ['B365H', 'B365A', 'Diff_S'],\n    'trainzonder_odds_met_balancing': ['Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FTG', 'Diff_FPG', 'Diff_HPG', 'Diff_FRDEF', 'Diff_FRATT'],\n    'trainzonder_odds_zonder_balancing': ['Diff_S', 'Diff_ST', 'Diff_C', 'Diff_FRATT']\n}\n\n# Hyperparameters voor elk model\nhyperparameters_dict = {\n    'trainmet_odds_met_balancing': {\n        'n_estimators': 129, 'learning_rate': 0.049876021595567685, 'max_depth': 10, 'subsample': 0.7849527378148702,\n        'min_child_weight': 2, 'colsample_bytree': 0.6120216069637563\n    },\n    'trainmet_odds_zonder_balancing': {\n        'n_estimators': 142, 'learning_rate': 0.014241138185489662, 'max_depth': 5, 'subsample': 0.6020914931801977,\n        'min_child_weight': 7, 'colsample_bytree': 0.5505854790099324\n    },\n    'trainzonder_odds_met_balancing': {\n        'n_estimators': 144, 'learning_rate': 0.018046202637800254, 'max_depth': 10, 'subsample': 0.7572792965555748,\n        'min_child_weight': 1, 'colsample_bytree': 0.90717604919467\n    },\n    'trainzonder_odds_zonder_balancing': {\n        'n_estimators': 176, 'learning_rate': 0.00516504117880041, 'max_depth': 6, 'subsample': 0.5260425851574494,\n        'min_child_weight': 7, 'colsample_bytree': 0.6163624968902534\n    }\n}\n\n# Functie om feature importance plot te genereren\ndef generate_feature_importance_plot(model, feature_names, variant_name):\n    # Haal de feature importances van het XGBoost model\n    importances = model.get_booster().get_score(importance_type='weight')\n    \n    # Sorteer de importances van hoog naar laag\n    sorted_importances = sorted(importances.items(), key=lambda x: x[1], reverse=True)\n    sorted_features = [item[0] for item in sorted_importances]\n    sorted_values = [item[1] for item in sorted_importances]\n    \n    # Normaliseer de importances zodat ze tussen 0 en 1 liggen\n    total_importance = sum(sorted_values)\n    normalized_values = [value / total_importance for value in sorted_values]\n    \n    # Maak de plot\n    plt.figure(figsize=(8, 6))\n    plt.barh(range(len(normalized_values)-1, -1, -1), normalized_values, align=\"center\", color='teal')\n    \n    # Stel de juiste feature-namen in\n    plt.yticks(range(len(normalized_values)), \n               [feature_names[int(feat[1:])] for feat in sorted_features], \n               rotation=0, ha=\"right\", fontsize=10)\n    \n    # Instellen van de x-as limieten en ticks\n    plt.xlim(0, 0.50)\n    plt.xticks([i * 0.10 for i in range(6)], fontsize=10)\n    \n    # Voeg waarden toe aan de balken\n    for i, value in enumerate(normalized_values[::-1]):\n        plt.text(value + 0.01, i, f\"{value:.2f}\", va='center', fontsize=9, color='black')\n    \n    # Verwijder rasterlijnen en overbodige assen\n    plt.grid(False)\n    plt.gca().spines['top'].set_visible(False)\n    plt.gca().spines['right'].set_visible(False)\n    \n    # Grafiektitel en labels\n    plt.title(f\"XGBoost Feature Importance\", fontsize=14)\n    plt.xlabel(\"Importance\", fontsize=12)\n    plt.ylabel(\"Feature\", fontsize=12)\n    \n    # Pas layout aan en toon de plot\n    plt.tight_layout()\n    plt.savefig(f\"XGFeature_Importance_{variant_name}.png\", bbox_inches='tight')\n    plt.show()\n    plt.close()\n\n\n\n# Functie om een model te trainen en alle plots te genereren\ndef train_and_generate_plots(X_train, y_train, X_test, y_test, variant_name):\n    # Haal de hyperparameters op\n    params = hyperparameters_dict[variant_name]\n    \n    # Train het model\n    model = XGBClassifier(**params, random_state=42)\n    model.fit(X_train, y_train)\n    \n    # Haal de juiste feature-namen op\n    feature_names = feature_names_dict[variant_name]\n\n    readable_name = variant_name_mapping.get(variant_name, variant_name)\n    \n    # Genereer de feature importance plot\n    generate_feature_importance_plot(model, feature_names, variant_name)\n    \n    # Voorspelling en evaluatie\n    y_pred = model.predict(X_test)\n    print(f\"Results for {variant_name}:\")\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n    print(classification_report(y_test, y_pred))\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(f\"Confusion Matrix XG-Boost - {readable_name}\")\n    plt.savefig(f\"XG confusion_matrix_{variant_name}.png\", bbox_inches='tight')\n    plt.show()\n    plt.close()\n\n# Loop door de datasets\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:\n        continue  # Skip testsets\n    \n    print(f\"\\nRunning XGBoost for {variant_name}\")\n    \n    # Selecteer de juiste testset\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n    else:\n        print(f\"Unknown variant name {variant_name}, skipping.\")\n        continue\n\n    # Zorg ervoor dat de data in de juiste vorm is\n    X_train = X_train.values\n    y_train = y_train.values\n    X_test = X_test.values\n    y_test = y_test.values\n    \n    # Train het model en genereer de plots\n    train_and_generate_plots(X_train, y_train, X_test, y_test, variant_name)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-26T10:47:07.080745Z","iopub.execute_input":"2024-11-26T10:47:07.081146Z","iopub.status.idle":"2024-11-26T10:47:13.264819Z","shell.execute_reply.started":"2024-11-26T10:47:07.081116Z","shell.execute_reply":"2024-11-26T10:47:13.263936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nimport matplotlib.pyplot as plt\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport numpy as np\n\n# Handmatig ingestelde feature-namen per dataset\nfeature_names_dict = {\n    'trainmet_odds_met_balancing': ['B365H', 'B365D', 'B365A', 'Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FPG', 'Diff_HPG'],\n    'trainmet_odds_zonder_balancing': ['B365H', 'B365A', 'Diff_S'],\n    'trainzonder_odds_met_balancing': ['Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FTG', 'Diff_FPG', 'Diff_HPG', 'Diff_FRDEF', 'Diff_FRATT'],\n    'trainzonder_odds_zonder_balancing': ['Diff_S', 'Diff_ST', 'Diff_C', 'Diff_FRATT']\n}\n\n# Hyperparameters voor elk model\nhyperparameters_dict = {\n    'trainmet_odds_met_balancing': {\n        'n_estimators': 129, 'learning_rate': 0.049876021595567685, 'max_depth': 10, 'subsample': 0.7849527378148702,\n        'min_child_weight': 2, 'colsample_bytree': 0.6120216069637563\n    },\n    'trainmet_odds_zonder_balancing': {\n        'n_estimators': 142, 'learning_rate': 0.014241138185489662, 'max_depth': 5, 'subsample': 0.6020914931801977,\n        'min_child_weight': 7, 'colsample_bytree': 0.5505854790099324\n    },\n    'trainzonder_odds_met_balancing': {\n        'n_estimators': 144, 'learning_rate': 0.018046202637800254, 'max_depth': 10, 'subsample': 0.7572792965555748,\n        'min_child_weight': 1, 'colsample_bytree': 0.90717604919467\n    },\n    'trainzonder_odds_zonder_balancing': {\n        'n_estimators': 176, 'learning_rate': 0.00516504117880041, 'max_depth': 6, 'subsample': 0.5260425851574494,\n        'min_child_weight': 7, 'colsample_bytree': 0.6163624968902534\n    }\n}\n\n# Functie om de SHAP summary plot voor Class 1 te verbeteren\ndef generate_class1_summary_plot(model, X_test, feature_names, variant_name):\n    # Maak een SHAP explainer\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X_test)\n    \n    # Bereken gemiddelde absolute SHAP-waarden voor Class 1\n    mean_shap_values_class1 = np.abs(shap_values[1]).mean(axis=0)\n    \n    # Stel figuurgrootte in voor een consistente breedte en hoogte\n    plt.figure(figsize=(9, 6))  # Pas de grootte aan voor de grafiek\n    \n    # Maak de balkgrafiek\n    plt.barh(feature_names, mean_shap_values_class1, color='purple')\n    \n    # Zet de belangrijkste feature bovenaan\n    plt.gca().invert_yaxis()  # Om de belangrijkste feature bovenaan te zetten\n    \n    # Pas de stijl van de grafiek aan:\n    plt.xlabel(\"Mean(|SHAP value|) (Impact on Model Output Magnitude)\", fontsize=12)\n    plt.title(f\"SHAP Summary (Class 1) - {variant_name}\", fontsize=14)\n    \n    # Verberg de grid en verbeter de layout\n    plt.grid(False)  # Verwijder de grid\n    plt.gca().spines['top'].set_visible(False)  # Verberg bovenste randlijn\n    plt.gca().spines['right'].set_visible(False)  # Verberg rechter randlijn\n    plt.gca().spines['left'].set_visible(True)  # Laat linker randlijn staan (voor de y-as)\n    plt.gca().spines['bottom'].set_visible(True)  # Laat onderrandlijn staan (voor de x-as)\n    \n    # Toon de grafiek\n    plt.show()  # Toon de grafiek\n    plt.savefig(f\"XGshap_summary_bar_class1_{variant_name}.png\", bbox_inches='tight')  # Sla de grafiek op met hoge resolutie\n    plt.close()\n\n\n\n# Functie om SHAP-plots te genereren en op te slaan\ndef generate_and_save_shap_plots(model, X_test, feature_names, variant_name):\n    # Maak een SHAP explainer\n    explainer = shap.TreeExplainer(model)\n    shap_values = explainer.shap_values(X_test)\n    \n    # 1. Standaard SHAP-summary-plot\n    plt.figure(figsize=(12, 6))  # Stel figuurgrootte in\n    shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)\n    plt.title(f\"SHAP Summary Plot - {variant_name}\")\n    plt.show()\n    plt.savefig(f\"XGshap_summary_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n    # 2. SHAP-summary-plot specifiek voor shap_values[1]\n    plt.figure(figsize=(12, 6))  # Stel figuurgrootte in\n    shap.summary_plot(shap_values[1], X_test, feature_names=feature_names, show=False)\n    plt.title(f\"SHAP Summary (Class 1) - {variant_name}\")\n    plt.show()\n    plt.savefig(f\"XGshap_summary_class1_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n# Functie om een model te trainen en alle plots te genereren\ndef train_and_generate_plots(X_train, y_train, X_test, y_test, variant_name):\n    # Haal de hyperparameters op\n    params = hyperparameters_dict[variant_name]\n    \n    # Train het model\n    model = XGBClassifier(**params, random_state=42)\n    model.fit(X_train, y_train)\n    \n    # Haal de juiste feature-namen op\n    feature_names = feature_names_dict[variant_name]\n    \n    # Genereer SHAP-plots\n    generate_and_save_shap_plots(model, X_test, feature_names, variant_name)\n    \n    # Genereer de specifieke balkgrafiek voor Class 1\n    generate_class1_summary_plot(model, X_test, feature_names, variant_name)\n    \n    # Voorspelling en evaluatie\n    y_pred = model.predict(X_test)\n    print(f\"Results for {variant_name}:\")\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n    print(classification_report(y_test, y_pred))\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(f\"XGConfusion Matrix for {variant_name}\")\n    plt.show()\n    plt.savefig(f\"confusion_matrix_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n# Loop door de datasets\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:\n        continue  # Skip testsets\n    \n    print(f\"\\nRunning XGBoost for {variant_name}\")\n    \n    # Selecteer de juiste testset\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n    else:\n        print(f\"Unknown variant name {variant_name}, skipping.\")\n        continue\n\n    # Zorg ervoor dat de data in de juiste vorm is\n    X_train = X_train.values\n    y_train = y_train.values\n    X_test = X_test.values\n    y_test = y_test.values\n    \n    # Train het model en genereer de plots\n    train_and_generate_plots(X_train, y_train, X_test, y_test, variant_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T22:38:13.534055Z","iopub.execute_input":"2024-11-21T22:38:13.534368Z","iopub.status.idle":"2024-11-21T22:38:36.995700Z","shell.execute_reply.started":"2024-11-21T22:38:13.534342Z","shell.execute_reply":"2024-11-21T22:38:36.994835Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stel de random seed in voor consistentie\nSEED = 42  # Kies een vaste seed voor consistentie\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# Mapping van variant_names naar beschrijvingen\nvariant_name_mapping = {\n    'trainmet_odds_met_balancing': 'C1',\n    'trainmet_odds_zonder_balancing': 'C2',\n    'trainzonder_odds_met_balancing': 'C3',\n    'trainzonder_odds_zonder_balancing': 'C4'\n}\n\nfeature_names_dict = {\n    'trainmet_odds_met_balancing': ['B365H', 'B365D', 'B365A', 'Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FPG', 'Diff_HPG'],\n    'trainmet_odds_zonder_balancing': ['B365H', 'B365A', 'Diff_S'],\n    'trainzonder_odds_met_balancing': ['Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FTG', 'Diff_FPG', 'Diff_HPG', 'Diff_FRDEF', 'Diff_FRATT'],\n    'trainzonder_odds_zonder_balancing': ['Diff_S', 'Diff_ST', 'Diff_C', 'Diff_FRATT']\n}\n\n# Definieer de ideale hyperparameters voor de TabNet-modellen\ntabnet_hyperparameters = {\n    'trainmet_odds_met_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 8, 'gamma': 0.02, 'n_shared': 2, 'lambda_sparse': 7.891392918016076e-05, 'patienceScheduler': 9, 'max_epochs': 50, 'patience': 7\n    },\n    'trainmet_odds_zonder_balancing': {\n        'mask_type': 'entmax', 'n_da': 16, 'n_steps': 5, 'gamma': 0.1, 'n_shared': 3,\n        'lambda_sparse': 0.00035632918778922634, 'patienceScheduler': 8, 'max_epochs': 29, 'patience': 5\n    },\n    'trainzonder_odds_met_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 8, 'gamma': 0.01, 'n_shared': 1,\n        'lambda_sparse': 5.097139359389593e-05, 'patienceScheduler': 10, 'max_epochs': 50, 'patience': 10\n    },\n    'trainzonder_odds_zonder_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 16, 'n_steps': 3, 'gamma': 0.060000000000000005, 'n_shared': 1, 'lambda_sparse': 0.0002059204000149221, 'patienceScheduler': 10, 'max_epochs': 16, 'patience': 9\n    }\n}\n\n# Functie om het model te laden en de confusion matrix te genereren voor TabNet\ndef load_and_evaluate_tabnet_confusion_matrix(X_train, y_train, X_test, y_test, variant_name):\n    # Haal de hyperparameters op voor de huidige variant\n    params = tabnet_hyperparameters[variant_name]\n    \n    # Laad het TabNet model met de opgegeven hyperparameters\n    tabnet_model = TabNetClassifier(\n        n_d=params['n_da'],\n        n_a=params['n_da'],\n        n_steps=params['n_steps'],\n        gamma=params['gamma'],\n        lambda_sparse=params['lambda_sparse'],\n        optimizer_fn=torch.optim.Adam,\n        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n        mask_type=params['mask_type'],\n        n_shared=params['n_shared'],\n        scheduler_params=dict(\n            patience=params['patienceScheduler'],\n            min_lr=1e-5,\n            factor=0.5,\n        ),\n        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n        verbose=0,\n        seed=SEED,  # Seed toegevoegd\n    )\n\n    # Train het model met de opgegeven hyperparameters\n    tabnet_model.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        max_epochs=params['max_epochs'],\n        patience=params['patience'],\n        batch_size=64\n    )\n\n    # Voorspellingen doen\n    feature_names = feature_names_dict[variant_name]\n    \n    y_pred_tabnet = tabnet_model.predict(X_test)\n    \n    importances = tabnet_model.feature_importances_\n    \n    indices = importances.argsort()[::1]\n    \n    plt.figure(figsize=(8, 6))\n    plt.xlim(0, 0.50)\n    plt.xticks([i * 0.10 for i in range(6)], fontsize=10)  \n    \n    plt.yticks(range(len(indices)), [feature_names[i] for i in indices], rotation=0, ha=\"right\", fontsize=10)\n    for i, value in enumerate(importances[indices]):\n        plt.text(value + 0.01, i, f\"{value:.2f}\", va='center', fontsize=9, color='black')\n    # Maak de grafiek\n    importance = plt.barh(range(len(indices)), importances[indices], align=\"center\", color='teal')\n    \n    # Verwijder de rasterlijnen\n    plt.grid(False)\n    \n    # Verwijder de bovenste en rechter grafieklijnen\n    plt.gca().spines['top'].set_visible(False)\n    plt.gca().spines['right'].set_visible(False)\n      # Verwijder getallen op de x-as\n    \n    # Grafiektitel en labels\n    plt.title(f\"Feature Importance - TabNet\", fontsize=14)\n    plt.xlabel(\"Importance\", fontsize=12)\n    plt.ylabel(\"Feature\", fontsize=12)\n    \n    plt.tight_layout()\n    plt.savefig(f\"Tabnet_Feature_Importance_{variant_name}.png\", bbox_inches='tight')\n    plt.show()\n    plt.close()\n\n    readable_name = variant_name_mapping.get(variant_name, variant_name)\n\n    # Evaluatie en metrics (enkel confusion matrix hier)\n    cm = confusion_matrix(y_test, y_pred_tabnet)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(f\"Confusion Matrix TabNet - {readable_name}\")\n    plt.savefig(f\"Tabnet_ConfusionMatrix{variant_name}.png\", bbox_inches='tight')\n    plt.show()\n\n    class_names = [\"class_1\", \"class_2\", \"class_3\"]\n    print(f\"Confusion Matrix for {variant_name}:\")\n    print(cm)\n\n# Voor elke dataset variant (alleen confusion matrix zonder SHAP plots)\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip testsets\n        continue\n\n    print(f\"\\nRunning TabNet on dataset variant: {variant_name}\")\n\n    # Bepaal het testset op basis van de training variant\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n    else:\n        print(f\"Unknown variant name {variant_name}, skipping.\")\n        continue\n\n    # Zorg ervoor dat de data in de juiste vorm is (arrays)\n    X_train = X_train.values\n    y_train = y_train.values\n    X_test = X_test.values\n    y_test = y_test.values\n\n    # Train model en genereer alleen confusion matrix\n    load_and_evaluate_tabnet_confusion_matrix(X_train, y_train, X_test, y_test, variant_name)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-26T11:07:04.630162Z","iopub.execute_input":"2024-11-26T11:07:04.631137Z","iopub.status.idle":"2024-11-26T11:08:03.176654Z","shell.execute_reply.started":"2024-11-26T11:07:04.631082Z","shell.execute_reply":"2024-11-26T11:08:03.175648Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Stel de random seed in voor consistentie\nSEED = 42  # Kies een vaste seed voor consistentie\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nfeature_names_dict = {\n    'trainmet_odds_met_balancing': ['B365H', 'B365D', 'B365A', 'Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FPG', 'Diff_HPG'],\n    'trainmet_odds_zonder_balancing': ['B365H', 'B365A', 'Diff_S'],\n    'trainzonder_odds_met_balancing': ['Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FTG', 'Diff_FPG', 'Diff_HPG', 'Diff_FRDEF', 'Diff_FRATT'],\n    'trainzonder_odds_zonder_balancing': ['Diff_S', 'Diff_ST', 'Diff_C', 'Diff_FRATT']\n}\n\n# Definieer de ideale hyperparameters voor de TabNet-modellen\ntabnet_hyperparameters = {\n    'trainmet_odds_met_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 8, 'gamma': 0.02, 'n_shared': 2, 'lambda_sparse': 7.891392918016076e-05, 'patienceScheduler': 9, 'max_epochs': 50, 'patience': 7\n    },\n    'trainmet_odds_zonder_balancing': {\n        'mask_type': 'entmax', 'n_da': 16, 'n_steps': 5, 'gamma': 0.1, 'n_shared': 3,\n        'lambda_sparse': 0.00035632918778922634, 'patienceScheduler': 8, 'max_epochs': 29, 'patience': 5\n    },\n    'trainzonder_odds_met_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 8, 'gamma': 0.01, 'n_shared': 1,\n        'lambda_sparse': 5.097139359389593e-05, 'patienceScheduler': 10, 'max_epochs': 50, 'patience': 10\n    },\n    'trainzonder_odds_zonder_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 16, 'n_steps': 3, 'gamma': 0.060000000000000005, 'n_shared': 1, 'lambda_sparse': 0.0002059204000149221, 'patienceScheduler': 10, 'max_epochs': 16, 'patience': 9\n    }\n}\n\n# Functie om een SHAP-plot te genereren voor het TabNet model\n\n\ndef generate_shap_plot_tabnet(model, X_test, feature_names, variant_name):\n    # Gebruik de predict functie van TabNet om voorspellingen te krijgen\n    explainer = shap.Explainer(model.predict, X_test)  # Gebruik de predict functie van het model\n    shap_values = explainer(X_test)\n    \n    # Print shapes voor debugging\n    print(\"SHAP values shape:\", shap_values.values.shape)\n    print(\"X_test shape:\", X_test.shape)\n    \n    # 1. Standaard SHAP samenvattingsplot voor alle klassen\n    plt.figure(figsize=(12, 6))  # Zet de figuurgrootte\n    shap.summary_plot(shap_values.values, X_test, feature_names=feature_names, show=False)\n    plt.title(f\"SHAP Summary Plot - {variant_name}\")\n    plt.show()\n    plt.savefig(f\"TabNet_shap_summary_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n    \n     # 1. Standaard SHAP-summary-plot\n    plt.figure(figsize=(12, 6))  # Stel figuurgrootte in\n    shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)\n    plt.title(f\"SHAP Summary Plot - {variant_name}\")\n    plt.show()\n    plt.savefig(f\"XGshap_summary_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n    \n    # 2\n    plt.figure(figsize=(12, 6))  # Stel figuurgrootte in\n    shap.summary_plot(shap_values.values[1], X_test, feature_names=feature_names, show=False)\n    plt.title(f\"SHAP Summary (Class 1) - {variant_name}\")\n    plt.show()\n    plt.savefig(f\"XGshap_summary_class1_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n        \n# Functie om het model te laden en SHAP-plot te genereren voor TabNet\ndef load_and_evaluate_tabnet(X_train, y_train, X_test, y_test, feature_names, variant_name):\n    # Haal de hyperparameters op voor de huidige variant\n    params = tabnet_hyperparameters[variant_name]\n    \n    # Laad het TabNet model met de opgegeven hyperparameters\n    tabnet_model = TabNetClassifier(\n        n_d=params['n_da'], \n        n_a=params['n_da'], \n        n_steps=params['n_steps'], \n        gamma=params['gamma'],\n        lambda_sparse=params['lambda_sparse'], \n        optimizer_fn=torch.optim.Adam,\n        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n        mask_type=params['mask_type'], \n        n_shared=params['n_shared'],\n        scheduler_params=dict(\n            patience=params['patienceScheduler'],\n            min_lr=1e-5,\n            factor=0.5,\n        ),\n        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n        verbose=0,\n        seed=SEED,  # Seed toegevoegd\n    )\n    \n    # Train het model met de opgegeven hyperparameters\n    tabnet_model.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        max_epochs=params['max_epochs'],\n        patience=params['patience'],\n        batch_size=64\n    )\n    \n    # Voorspellingen doen\n    y_pred_tabnet = tabnet_model.predict(X_test)\n    \n    # Genereer SHAP plots\n    generate_shap_plot_tabnet(tabnet_model, X_test, feature_names, variant_name)\n    \n    # Confusion Matrix en classification report\n    cm = confusion_matrix(y_test, y_pred_tabnet)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(f\"Confusion Matrix: Tuned TabNet for {variant_name}\")\n    plt.show()\n\n    class_names = [\"class_1\", \"class_2\", \"class_3\"]\n    print(classification_report(y_test, y_pred_tabnet, target_names=class_names))\n\n# Voor elke dataset variant\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip testsets\n        continue  \n\n    print(f\"\\nRunning TabNet on dataset variant: {variant_name}\")\n\n    # Bepaal het testset op basis van de training variant\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0].head(5)  # Gebruik alleen de eerste 5 instances\n        y_test = datasets['testmet_odds_met_balancing'][1].head(5)  # Gebruik alleen de eerste 5 instances\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0].head(5)  # Gebruik alleen de eerste 5 instances\n        y_test = datasets['testmet_odds_zonder_balancing'][1].head(5)  # Gebruik alleen de eerste 5 instances\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0].head(5)  # Gebruik alleen de eerste 5 instances\n        y_test = datasets['testzonder_odds_met_balancing'][1].head(5)  # Gebruik alleen de eerste 5 instances\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0].head(5)  # Gebruik alleen de eerste 5 instances\n        y_test = datasets['testzonder_odds_zonder_balancing'][1].head(5)  # Gebruik alleen de eerste 5 instances\n    \n    X_train = X_train.values\n    y_train = y_train.values\n    X_test = X_test.values\n    y_test = y_test.values\n\n    # Run de evaluatie voor TabNet\n    load_and_evaluate_tabnet(X_train, y_train, X_test, y_test, feature_names_dict[variant_name], variant_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T14:47:55.812702Z","iopub.execute_input":"2024-11-21T14:47:55.813037Z","iopub.status.idle":"2024-11-21T14:48:24.350504Z","shell.execute_reply.started":"2024-11-21T14:47:55.813006Z","shell.execute_reply":"2024-11-21T14:48:24.349315Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the hyperparameters for the TabNet models\nimport shap\nimport matplotlib.pyplot as plt\nimport torch\nimport numpy as np\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score, ConfusionMatrixDisplay\n\n# Stel de random seed in voor consistentie\nSEED = 42  # Kies een vaste seed voor consistentie\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nfeature_names_dict = {\n    'trainmet_odds_met_balancing': ['B365H', 'B365D', 'B365A', 'Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FPG', 'Diff_HPG'],\n    'trainmet_odds_zonder_balancing': ['B365H', 'B365A', 'Diff_S'],\n    'trainzonder_odds_met_balancing': ['Diff_S', 'Diff_ST', 'Diff_F', 'Diff_C', 'Diff_Y', 'Diff_FTG', 'Diff_FPG', 'Diff_HPG', 'Diff_FRDEF', 'Diff_FRATT'],\n    'trainzonder_odds_zonder_balancing': ['Diff_S', 'Diff_ST', 'Diff_C', 'Diff_FRATT']\n}\n\nfeature_names = feature_names_dict[variant_name]\nprint(f\"Feature names for {variant_name}: {feature_names}\")\n\n# Definieer de ideale hyperparameters voor de TabNet-modellen\ntabnet_hyperparameters = {\n    'trainmet_odds_met_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 8, 'gamma': 0.02, 'n_shared': 2, 'lambda_sparse': 7.891392918016076e-05, 'patienceScheduler': 9, 'max_epochs': 50, 'patience': 7\n    },\n    'trainmet_odds_zonder_balancing': {\n        'mask_type': 'entmax', 'n_da': 16, 'n_steps': 5, 'gamma': 0.1, 'n_shared': 3,\n        'lambda_sparse': 0.00035632918778922634, 'patienceScheduler': 8, 'max_epochs': 29, 'patience': 5\n    },\n    'trainzonder_odds_met_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 8, 'gamma': 0.01, 'n_shared': 1,\n        'lambda_sparse': 5.097139359389593e-05, 'patienceScheduler': 10, 'max_epochs': 50, 'patience': 10\n    },\n    'trainzonder_odds_zonder_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 16, 'n_steps': 3, 'gamma': 0.060000000000000005, 'n_shared': 1, 'lambda_sparse': 0.0002059204000149221, 'patienceScheduler': 10, 'max_epochs': 16, 'patience': 9\n    }\n}\n\n\n# Functie om een SHAP-plot te genereren voor het TabNet model\ndef generate_shap_plot_tabnet(model, X_test, feature_names, variant_name):\n    # Gebruik de predict functie van TabNet om voorspellingen te krijgen\n    explainer = shap.Explainer(model.predict, X_test)  # Gebruik de predict functie van het model\n    shap_values = explainer(X_test)\n\n    # 1. Standaard SHAP-summary-plot\n    plt.figure(figsize=(12, 6))  # Stel figuurgrootte in\n    shap.summary_plot(shap_values, X_test, feature_names=feature_names, show=False)\n    plt.title(f\"SHAP Summary Plot - {variant_name}\")\n    plt.show()\n    plt.savefig(f\"TabNet_shap_summary_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n    # 2. SHAP-summary-plot specifiek voor shap_values[1] (Class 1)\n    plt.figure(figsize=(12, 6))  # Stel figuurgrootte in\n    shap.summary_plot(shap_values[1], X_test, feature_names=feature_names, show=False)\n    plt.title(f\"SHAP Summary (Class 1) - {variant_name}\")\n    plt.show()\n    plt.savefig(f\"TabNet_shap_summary_class1_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n    # 3. SHAP-balkgrafiek voor gemiddelde absolute SHAP-waarde voor Class 1\n    mean_shap_values_class1 = np.abs(shap_values[1].values).mean(axis=0)  # Gemiddelde absolute SHAP-waarde\n    plt.figure(figsize=(9, 6))  # Pas de grootte aan voor de grafiek\n    plt.barh(feature_names, mean_shap_values_class1, color='purple')\n    plt.gca().invert_yaxis()  # Zet de belangrijkste feature bovenaan\n    plt.xlabel(\"Mean(|SHAP value|) (Impact on Model Output Magnitude)\", fontsize=12)\n    plt.title(f\"SHAP Summary (Class 1) - {variant_name}\", fontsize=14)\n    plt.grid(False)  # Verwijder de grid\n    plt.gca().spines['top'].set_visible(False)\n    plt.gca().spines['right'].set_visible(False)\n    plt.gca().spines['left'].set_visible(True)\n    plt.gca().spines['bottom'].set_visible(True)\n    plt.show()\n    plt.savefig(f\"TabNet_shap_summary_bar_class1_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n# Functie om het model te laden en SHAP-plot te genereren voor TabNet\ndef load_and_evaluate_tabnet(X_train, y_train, X_test, y_test, feature_names, variant_name):\n    # Haal de hyperparameters op voor de huidige variant\n    params = tabnet_hyperparameters[variant_name]\n    \n    # Laad het TabNet model met de opgegeven hyperparameters\n    tabnet_model = TabNetClassifier(\n        n_d=params['n_da'], \n        n_a=params['n_da'], \n        n_steps=params['n_steps'], \n        gamma=params['gamma'],\n        lambda_sparse=params['lambda_sparse'], \n        optimizer_fn=torch.optim.Adam,\n        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n        mask_type=params['mask_type'], \n        n_shared=params['n_shared'],\n        scheduler_params=dict(\n            patience=params['patienceScheduler'],\n            min_lr=1e-5,\n            factor=0.5,\n        ),\n        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n        verbose=0,\n        seed=SEED,  # Seed toegevoegd\n    )\n    \n    # Train het model met de opgegeven hyperparameters\n    tabnet_model.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        max_epochs=params['max_epochs'],\n        patience=params['patience'],\n        batch_size=64\n    )\n    \n    # Voorspellingen doen\n    y_pred_tabnet = tabnet_model.predict(X_test)\n    \n    # Genereer SHAP plots\n    generate_shap_plot_tabnet(tabnet_model, X_test, feature_names, variant_name)\n    \n    # Evaluatie en metrics\n    accuracy = accuracy_score(y_test, y_pred_tabnet)\n    f1 = f1_score(y_test, y_pred_tabnet, average='macro')\n    print(f\"{variant_name} - Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}\")\n    \n    # Confusion Matrix en classification report\n    cm = confusion_matrix(y_test, y_pred_tabnet)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(f\"Confusion Matrix: Tuned TabNet for {variant_name}\")\n    plt.show()\n\n    class_names = [\"class_1\", \"class_2\", \"class_3\"]\n    print(classification_report(y_test, y_pred_tabnet, target_names=class_names))\n\n# Voor elke dataset variant\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip testsets\n        continue  \n\n    print(f\"\\nRunning TabNet on dataset variant: {variant_name}\")\n\n    # Bepaal het testset op basis van de training variant\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n    else:\n        print(f\"Unknown variant name {variant_name}, skipping.\")\n        continue\n\n    # Zorg ervoor dat de data in de juiste vorm is (arrays)\n    X_train = X_train.values\n    y_train = y_train.values\n    X_test = X_test.values\n    y_test = y_test.values\n\n    # Train model en genereer SHAP plot\n    load_and_evaluate_tabnet(X_train, y_train, X_test, y_test, feature_names, variant_name)\n","metadata":{"execution":{"iopub.status.busy":"2024-11-21T11:03:06.116928Z","iopub.execute_input":"2024-11-21T11:03:06.117231Z","iopub.status.idle":"2024-11-21T13:59:49.671067Z","shell.execute_reply.started":"2024-11-21T11:03:06.117205Z","shell.execute_reply":"2024-11-21T13:59:49.669933Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nimport matplotlib.pyplot as plt\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nimport torch\nimport numpy as np\n\n# Stel de random seed in voor consistentie\nSEED = 42  # Kies een vaste seed voor consistentie\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# Definieer de ideale hyperparameters voor de TabNet-modellen\ntabnet_hyperparameters = {\n    'trainmet_odds_met_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 8, 'gamma': 0.02, 'n_shared': 2,\n        'lambda_sparse': 7.891392918016076e-05, 'patienceScheduler': 9, 'max_epochs': 50, 'patience': 7\n    },\n    'trainmet_odds_zonder_balancing': {\n        'mask_type': 'entmax', 'n_da': 16, 'n_steps': 5, 'gamma': 0.1, 'n_shared': 3,\n        'lambda_sparse': 0.00035632918778922634, 'patienceScheduler': 8, 'max_epochs': 29, 'patience': 5\n    },\n    'trainzonder_odds_met_balancing': {\n        'mask_type': 'sparsemax', 'n_da': 24, 'n_steps': 8, 'gamma': 0.01, 'n_shared': 1,\n        'lambda_sparse': 5.097139359389593e-05, 'patienceScheduler': 10, 'max_epochs': 50, 'patience': 10\n    },\n    'trainzonder_odds_zonder_balancing': {\n      'mask_type': 'sparsemax', 'n_da': 16, 'n_steps': 3, 'gamma': 0.060000000000000005, 'n_shared': 1, 'lambda_sparse': 0.0002059204000149221, 'patienceScheduler': 10, 'max_epochs': 16, 'patience': 9\n    }\n}\n\n# Functie om een SHAP-plot te genereren voor het TabNet model\ndef generate_shap_plot_tabnet(model, X_test):\n    # Gebruik de predict functie van TabNet om voorspellingen te krijgen\n    explainer = shap.Explainer(model.predict, X_test)  # Gebruik de predict functie van het model\n    shap_values = explainer(X_test)\n    shap.summary_plot(shap_values, X_test)\n\n# Functie voor evaluatie (Accuracy)\ndef evaluate(y_true, y_pred, model_name):\n    accuracy = accuracy_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred, average='macro')\n    print(f\"{model_name} - Accuracy: {accuracy:.4f}, F1-score: {f1:.4f}\")\n\n# Functie om het model te laden en SHAP-plot te genereren voor TabNet\ndef load_and_evaluate_tabnet(X_train, y_train, X_test, y_test, variant_name):\n    # Haal de hyperparameters op voor de huidige variant\n    params = tabnet_hyperparameters[variant_name]\n\n    # Laad het TabNet model met de opgegeven hyperparameters\n    tabnet_model = TabNetClassifier(\n        n_d=params['n_da'], \n        n_a=params['n_da'], \n        n_steps=params['n_steps'], \n        gamma=params['gamma'],\n        lambda_sparse=params['lambda_sparse'], \n        optimizer_fn=torch.optim.Adam,\n        optimizer_params=dict(lr=2e-2, weight_decay=1e-5),\n        mask_type=params['mask_type'], \n        n_shared=params['n_shared'],\n        scheduler_params=dict(\n            patience=params['patienceScheduler'],\n            min_lr=1e-5,\n            factor=0.5,\n        ),\n        scheduler_fn=torch.optim.lr_scheduler.ReduceLROnPlateau,\n        verbose=0,\n        seed=SEED,  # Seed toegevoegd\n    )\n    \n    # Train het model met de opgegeven hyperparameters\n    tabnet_model.fit(\n        X_train, y_train,\n        eval_set=[(X_test, y_test)],\n        max_epochs=params['max_epochs'],\n        patience=params['patience'],\n        batch_size=64\n    )\n    \n    # Voorspellingen doen\n    y_pred_tabnet = tabnet_model.predict(X_test)\n    \n    # Genereer SHAP plot\n    generate_shap_plot_tabnet(tabnet_model, X_test)\n    \n    # Evaluatie en metrics\n    evaluate(y_test, y_pred_tabnet, f\"Tuned TabNet for {variant_name}\")\n\n    # Confusion Matrix en classification report\n    cm = confusion_matrix(y_test, y_pred_tabnet)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot(cmap='Blues')\n    plt.title(f\"Confusion Matrix: Tuned TabNet for {variant_name}\")\n    plt.show()\n\n    class_names = [\"class_1\", \"class_2\", \"class_3\"]\n    print(classification_report(y_test, y_pred_tabnet, target_names=class_names))\n\n# Voor elke dataset variant\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip test variants\n        continue  \n\n    print(f\"\\nRunning TabNet on dataset variant: {variant_name}\")\n\n    # Bepaal het testset op basis van de training variant\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test = datasets['testmet_odds_met_balancing'][0]\n        y_test = datasets['testmet_odds_met_balancing'][1]\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test = datasets['testmet_odds_zonder_balancing'][0]\n        y_test = datasets['testmet_odds_zonder_balancing'][1]\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test = datasets['testzonder_odds_met_balancing'][0]\n        y_test = datasets['testzonder_odds_met_balancing'][1]\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test = datasets['testzonder_odds_zonder_balancing'][0]\n        y_test = datasets['testzonder_odds_zonder_balancing'][1]\n    else:\n        print(f\"Unknown variant name {variant_name}, skipping.\")\n        continue\n\n    # Zorg ervoor dat de data in de juiste vorm is (arrays)\n    X_train = X_train.values\n    y_train = y_train.values\n    X_test = X_test.values\n    y_test = y_test.values\n\n    # Train model en genereer SHAP plot\n    load_and_evaluate_tabnet(X_train, y_train, X_test, y_test, variant_name)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-11-20T21:03:37.916658Z","iopub.execute_input":"2024-11-20T21:03:37.917351Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shap\nimport matplotlib.pyplot as plt\nfrom pytorch_tabnet.tab_model import TabNetClassifier\nimport torch\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\nimport pandas as pd\n\n# Stel de random seed in voor consistentie\nSEED = 42\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed(SEED)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n# Functie om SHAP-plot te genereren voor TabNet\ndef generate_shap_plot_tabnet(model, X_test, feature_names, variant_name):\n    explainer = shap.Explainer(model.predict, X_test)\n    shap_values = explainer(X_test)\n    shap.summary_plot(shap_values, X_test, feature_names=feature_names)\n    plt.title(f\"SHAP Summary for {variant_name} (TabNet)\", fontsize=14)\n    plt.show()\n    plt.savefig(f\"SHAP_TabNet_Summary_{variant_name}.png\", bbox_inches='tight')\n    plt.close()\n\n# Functie voor modeltraining en evaluatie\ndef train_and_evaluate_tabnet(X_train, y_train, X_test, y_test, variant_name, feature_names):\n    # Laad het TabNet model met de opgegeven hyperparameters\n    tabnet_model = TabNetClassifier(\n        **tabnet_hyperparameters[variant_name],\n        seed=SEED\n    )\n    \n    # Train het TabNet model\n    tabnet_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n                     max_epochs=tabnet_hyperparameters[variant_name]['max_epochs'], \n                     patience=tabnet_hyperparameters[variant_name]['patience'])\n    \n    # Genereer SHAP plot voor TabNet\n    generate_shap_plot_tabnet(tabnet_model, X_test, feature_names, variant_name)\n\n    # Voorspellingen doen\n    y_pred_tabnet = tabnet_model.predict(X_test)\n\n    # Evaluatie en metrics\n    print(f\"Results for {variant_name} (TabNet):\")\n    print(f\"Accuracy: {accuracy_score(y_test, y_pred_tabnet)}\")\n    print(classification_report(y_test, y_pred_tabnet))\n\n    # Confusion Matrix\n    cm_tabnet = confusion_matrix(y_test, y_pred_tabnet)\n    disp_tabnet = ConfusionMatrixDisplay(confusion_matrix=cm_tabnet)\n    disp_tabnet.plot(cmap='Blues')\n    plt.title(f\"Confusion Matrix for {variant_name} (TabNet)\")\n    plt.show()\n\n# Itereer door de datasets voor verschillende varianten\nfor variant_name, (X_train, y_train) in datasets.items():\n    if 'test' in variant_name:  # Skip test datasets\n        continue\n\n    print(f\"\\nRunning TabNet on dataset variant: {variant_name}\")\n\n    if variant_name == 'trainmet_odds_met_balancing':\n        X_test, y_test = datasets['testmet_odds_met_balancing']\n    elif variant_name == 'trainmet_odds_zonder_balancing':\n        X_test, y_test = datasets['testmet_odds_zonder_balancing']\n    elif variant_name == 'trainzonder_odds_met_balancing':\n        X_test, y_test = datasets['testzonder_odds_met_balancing']\n    elif variant_name == 'trainzonder_odds_zonder_balancing':\n        X_test, y_test = datasets['testzonder_odds_zonder_balancing']\n\n    # Zorg ervoor dat de data in de juiste vorm is (DataFrame)\n    feature_names = feature_names_dict[variant_name]\n    X_train = pd.DataFrame(X_train, columns=feature_names)\n    X_test = pd.DataFrame(X_test, columns=feature_names)\n\n    # Train en evalueer het TabNet model\n    train_and_evaluate_tabnet(X_train, y_train, X_test, y_test, variant_name, feature_names)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom scipy.stats import zscore\n\n# Functie om uitbijters op basis van Z-score te verwijderen\ndef remove_outliers_zscore(df, threshold=3):\n    # Bereken de Z-score voor elke kolom in de DataFrame (alleen numerieke kolommen)\n    z_scores = np.abs(zscore(df.select_dtypes(include=[np.number])))  # Zorg ervoor dat we alleen numerieke kolommen gebruiken\n    \n    # Verwijder de rijen waar de Z-score groter is dan de drempel\n    df_no_outliers = df[(z_scores < threshold).all(axis=1)]\n    return df_no_outliers\n\n# Stel dat final_training je oorspronkelijke DataFrame is\n# Gebruik de functie om de uitbijters te verwijderen\nfinal_training_no_outliers = remove_outliers_zscore(train_data, threshold=3)\n\nprint(\"Data zonder uitbijters:\")\nprint(final_training_no_outliers)\nprint(final_training_no_outliers.shape)","metadata":{"execution":{"iopub.status.busy":"2024-11-08T13:22:24.436534Z","iopub.execute_input":"2024-11-08T13:22:24.437476Z","iopub.status.idle":"2024-11-08T13:22:24.468796Z","shell.execute_reply.started":"2024-11-08T13:22:24.437433Z","shell.execute_reply":"2024-11-08T13:22:24.467864Z"},"trusted":true},"outputs":[],"execution_count":null}]}